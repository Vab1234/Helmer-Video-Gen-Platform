{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92beca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.107.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests python-dotenv openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5611b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--prompt PROMPT] [--queries QUERIES]\n",
      "                             [--out OUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\JENNIFER\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3306c45ef2c8796af97fc5df342ae7a5d6b0ead35.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "collect_assets_unstructured.py\n",
    "\n",
    "- Input: a basic user prompt (unstructured).\n",
    "- Uses OpenAI to create 4-6 similar queries (fallback if OpenAI not available).\n",
    "- For each query: searches Pexels (photos + videos) and Freesound (audio).\n",
    "- Saves combined results to assets_unstructured.json.\n",
    "\n",
    "Notes:\n",
    "- Prefer the official APIs (we use them here).\n",
    "- This is intentionally simple and avoids heavy dependencies.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# OpenAI modern client\n",
    "from openai import OpenAI\n",
    "\n",
    "# --------------------------\n",
    "# Config & keys (from .env)\n",
    "# --------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "USE_OPENAI = bool(OPENAI_API_KEY)\n",
    "client = None\n",
    "if USE_OPENAI:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Endpoints & constants\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}\n",
    "\n",
    "# Limits - tune as needed\n",
    "MAX_QUERIES = 6\n",
    "PEXELS_PER_QUERY_PHOTOS = 4\n",
    "PEXELS_PER_QUERY_VIDEOS = 3\n",
    "FREESOUND_PER_QUERY = 3\n",
    "DELAY_BETWEEN_PROVIDER_CALLS = 0.25  # polite delay\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Helper: generate similar queries using OpenAI (or fallback)\n",
    "# --------------------------\n",
    "def generate_queries_via_openai(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Ask OpenAI to return a JSON array of short search queries similar to the prompt.\n",
    "    If OpenAI is not configured or fails, use a conservative fallback.\n",
    "    \"\"\"\n",
    "    if not USE_OPENAI or client is None:\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY a JSON array of short search query strings \"\n",
    "        \"(no explanation). Each string should be concise (1-6 words) and be a close variant or related \"\n",
    "        \"search term that would help find images/videos/audio for the brief. Return exactly the JSON array.\"\n",
    "    )\n",
    "    user = f\"Create {n} concise search queries for this brief: \\\"{prompt}\\\". Return JSON array only.\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        # safe access to message content\n",
    "        try:\n",
    "            content = resp.choices[0].message[\"content\"]\n",
    "        except Exception:\n",
    "            content = resp.choices[0].message.content if hasattr(resp.choices[0].message, \"content\") else \"\"\n",
    "        text = content.strip()\n",
    "        # strip code fences if present\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.splitlines()\n",
    "            if len(lines) >= 3:\n",
    "                text = \"\\n\".join(lines[1:-1])\n",
    "        queries = json.loads(text)\n",
    "        # sanitize and limit\n",
    "        cleaned = []\n",
    "        for q in queries:\n",
    "            if isinstance(q, str):\n",
    "                s = \" \".join(q.split()).strip()\n",
    "                if s:\n",
    "                    cleaned.append(s)\n",
    "            if len(cleaned) >= n:\n",
    "                break\n",
    "        if cleaned:\n",
    "            return cleaned\n",
    "        else:\n",
    "            return fallback_generate_queries(prompt, n)\n",
    "    except Exception as e:\n",
    "        # fallback\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "\n",
    "def fallback_generate_queries(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Conservative deterministic fallback: produce n query variants for the prompt.\n",
    "    \"\"\"\n",
    "    base = prompt.strip()\n",
    "    tokens = [t for t in base.split() if t]\n",
    "    queries = []\n",
    "    # 1: the original brief\n",
    "    queries.append(base)\n",
    "    # 2: add synonyms / context phrases\n",
    "    queries.append(base + \" street scene\")\n",
    "    queries.append(base + \" crowd\")\n",
    "    queries.append(base + \" city life\")\n",
    "    queries.append(base + \" people walking at street\")\n",
    "    # dedupe and limit\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        qn = \" \".join(q.split())\n",
    "        if qn.lower() not in seen:\n",
    "            seen.add(qn.lower())\n",
    "            final.append(qn)\n",
    "        if len(final) >= n:\n",
    "            break\n",
    "    return final\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Pexels API fetch helpers\n",
    "# --------------------------\n",
    "def pexels_search_photos(query: str, per_page: int = PEXELS_PER_QUERY_PHOTOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for p in data.get(\"photos\", [])[:per_page]:\n",
    "            items.append({\n",
    "                \"id\": f\"photo_{p.get('id')}\",\n",
    "                \"url\": p.get(\"src\", {}).get(\"original\") or p.get(\"src\", {}).get(\"large\"),\n",
    "                \"width\": p.get(\"width\"),\n",
    "                \"height\": p.get(\"height\"),\n",
    "                \"photographer\": p.get(\"photographer\"),\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": p\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS PHOTOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = PEXELS_PER_QUERY_VIDEOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for v in data.get(\"videos\", [])[:per_page]:\n",
    "            # pick best file (highest width*fps) if available\n",
    "            files = v.get(\"video_files\", []) or []\n",
    "            chosen = None\n",
    "            if files:\n",
    "                files_sorted = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)\n",
    "                chosen = files_sorted[0]\n",
    "            items.append({\n",
    "                \"id\": f\"video_{v.get('id')}\",\n",
    "                \"url\": (chosen.get(\"link\") if chosen else v.get(\"url\")),\n",
    "                \"duration\": v.get(\"duration\"),\n",
    "                \"width\": chosen.get(\"width\") if chosen else None,\n",
    "                \"height\": chosen.get(\"height\") if chosen else None,\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": v\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS VIDEOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Freesound API fetch helpers\n",
    "# --------------------------\n",
    "def freesound_search(query: str, page_size: int = FREESOUND_PER_QUERY) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    try:\n",
    "        r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for item in data.get(\"results\", [])[:page_size]:\n",
    "            previews = item.get(\"previews\", {}) or {}\n",
    "            preview_url = previews.get(\"preview-hq-mp3\") or previews.get(\"preview-hq-ogg\") or previews.get(\"preview-lq-mp3\")\n",
    "            items.append({\n",
    "                \"id\": f\"fs_{item.get('id')}\",\n",
    "                \"title\": item.get(\"name\"),\n",
    "                \"url\": preview_url,\n",
    "                \"duration\": item.get(\"duration\"),\n",
    "                \"uploader\": item.get(\"username\"),\n",
    "                \"tags\": item.get(\"tags\", []),\n",
    "                \"license\": item.get(\"license\"),\n",
    "                \"provider\": \"freesound\",\n",
    "                \"raw\": item\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[FREESOUND ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main pipeline\n",
    "# --------------------------\n",
    "def collect_assets_for_prompt(prompt: str, num_queries: int = MAX_QUERIES) -> Dict[str, Any]:\n",
    "    out = {\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_queries\": [],\n",
    "        \"results\": {},  # query -> {pexels: {photos:[], videos:[]}, freesound: {audios:[]}}\n",
    "        \"notes\": {}\n",
    "    }\n",
    "\n",
    "    # 1) generate queries\n",
    "    queries = generate_queries_via_openai(prompt, n=num_queries)\n",
    "    out[\"generated_queries\"] = queries\n",
    "\n",
    "    # 2) for each query, fetch from Pexels + Freesound\n",
    "    for q in queries:\n",
    "        qkey = q\n",
    "        out[\"results\"][qkey] = {\"pexels\": {\"photos\": [], \"videos\": []}, \"freesound\": {\"audios\": []}}\n",
    "        # Pexels photos\n",
    "        photos = pexels_search_photos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        videos = pexels_search_videos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        audios = freesound_search(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        out[\"results\"][qkey][\"pexels\"][\"photos\"] = photos\n",
    "        out[\"results\"][qkey][\"pexels\"][\"videos\"] = videos\n",
    "        out[\"results\"][qkey][\"freesound\"][\"audios\"] = audios\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLI / example usage\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Collect Pexels + Freesound assets for an unstructured prompt.\")\n",
    "    parser.add_argument(\"--prompt\", \"-p\", type=str, help=\"User prompt (e.g. 'bustling city with people')\", required=False)\n",
    "    parser.add_argument(\"--queries\", \"-q\", type=int, default=5, help=\"Number of similar queries to generate (default 5)\")\n",
    "    parser.add_argument(\"--out\", \"-o\", type=str, default=\"assets_unstructured.json\", help=\"Output JSON filename\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not args.prompt:\n",
    "        # interactive ask\n",
    "        user_prompt = input(\"Enter a prompt (e.g. 'bustling city with people'): \").strip()\n",
    "    else:\n",
    "        user_prompt = args.prompt.strip()\n",
    "\n",
    "    print(\"[RUN] Prompt:\", user_prompt)\n",
    "    plan = collect_assets_for_prompt(user_prompt, num_queries=args.queries)\n",
    "\n",
    "    # save output\n",
    "    with open(args.out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(plan, f, indent=2)\n",
    "\n",
    "    print(f\"[DONE] Saved results to {args.out}\")\n",
    "    # print summary\n",
    "    total_photos = sum(len(plan[\"results\"][q][\"pexels\"][\"photos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_videos = sum(len(plan[\"results\"][q][\"pexels\"][\"videos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_audios = sum(len(plan[\"results\"][q][\"freesound\"][\"audios\"]) for q in plan[\"generated_queries\"])\n",
    "    print(f\"Found {total_photos} photos, {total_videos} videos (Pexels), {total_audios} audio previews (Freesound) across {len(plan['generated_queries'])} queries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61acf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from typing import List, Dict, Any, Optional\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mutagen import File as MutagenFile  # for audio metadata\n",
    "\n",
    "# --- OpenAI modern client ---\n",
    "from openai import OpenAI\n",
    "\n",
    "# Try to import ultralytics YOLO (optional)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    _YOLO_AVAILABLE = True\n",
    "except Exception:\n",
    "    _YOLO_AVAILABLE = False\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"Please set OPENAI_API_KEY in your environment or .env file\")\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # change if you prefer another model\n",
    "\n",
    "# Pexels API endpoints\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "\n",
    "# Freesound endpoints\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VIDEOS_PER_QUERY = 3\n",
    "MAX_IMAGES_PER_QUERY = 3\n",
    "MAX_AUDIOS_PER_QUERY = 3\n",
    "MAX_QUERIES_PER_SHOT = 3\n",
    "MAX_SHOTS = 6\n",
    "\n",
    "# ---------------------\n",
    "# 1) OpenAI shot-splitting (structured JSON)\n",
    "# ---------------------\n",
    "def ask_model_for_shots(prompt_text: str, min_shots: int = 1, max_shots: int = 4) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Use OpenAI to return structured shots JSON (id, text_description, suggested_duration_seconds, keywords, style_tokens, negative_filters)\n",
    "    \"\"\"\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY valid JSON (no commentary). \"\n",
    "        f\"Given a short video brief, return an array of between {min_shots} and {max_shots} shots. \"\n",
    "        \"Each shot object must include the following keys: \"\n",
    "        '\"id\" (string), \"text_description\" (string), \"suggested_duration_seconds\" (integer), '\n",
    "        '\"keywords\" (array of strings), \"style_tokens\" (array of strings), \"negative_filters\" (array of strings).'\n",
    "    )\n",
    "    user = f\"Convert this brief into shots: \\\"{prompt_text}\\\". Return JSON only.\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=400,\n",
    "    )\n",
    "\n",
    "    # safe access to content\n",
    "    try:\n",
    "        content = resp.choices[0].message[\"content\"]\n",
    "    except Exception:\n",
    "        try:\n",
    "            content = resp.choices[0].message.content\n",
    "        except Exception:\n",
    "            content = resp.choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "    text = content.strip() if content else \"\"\n",
    "    # strip backticks if model wraps JSON in fences\n",
    "    if text.startswith(\"```\"):\n",
    "        lines = text.splitlines()\n",
    "        if len(lines) >= 3:\n",
    "            text = \"\\n\".join(lines[1:-1])\n",
    "\n",
    "    try:\n",
    "        shots = json.loads(text)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to parse JSON from model output: {e}\\n---\\n{text}\")\n",
    "\n",
    "    if not isinstance(shots, list):\n",
    "        raise RuntimeError(\"Model did not return a JSON array of shots.\")\n",
    "    return shots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 2) Query expansion\n",
    "# ---------------------\n",
    "def expand_queries_for_shot(shot: Dict[str, Any], max_queries: int = MAX_QUERIES_PER_SHOT) -> List[str]:\n",
    "    queries = []\n",
    "    text = shot.get(\"text_description\", \"\").strip()\n",
    "    if text:\n",
    "        queries.append(text)\n",
    "    keywords = shot.get(\"keywords\", []) or []\n",
    "    if keywords:\n",
    "        queries.append(\" \".join(keywords))\n",
    "        for k in keywords[:2]:\n",
    "            queries.append(k)\n",
    "    style_tokens = shot.get(\"style_tokens\", []) or []\n",
    "    if style_tokens and text:\n",
    "        queries.append(text + \" \" + \" \".join(style_tokens[:2]))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for q in queries:\n",
    "        qclean = \" \".join(q.split())\n",
    "        if qclean and qclean not in seen:\n",
    "            seen.add(qclean)\n",
    "            final.append(qclean)\n",
    "        if len(final) >= max_queries:\n",
    "            break\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 3) Pexels API helpers (fetch)\n",
    "# ---------------------\n",
    "def pexels_search_photos(query: str, per_page: int = MAX_IMAGES_PER_QUERY) -> Dict[str, Any]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = MAX_VIDEOS_PER_QUERY) -> Dict[str, Any]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def normalize_photo_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"id\": f\"photo_{item.get('id')}\",\n",
    "        \"type\": \"image\",\n",
    "        \"url\": item.get(\"src\", {}).get(\"original\") or item.get(\"src\", {}).get(\"large\"),\n",
    "        \"width\": item.get(\"width\"),\n",
    "        \"height\": item.get(\"height\"),\n",
    "        \"photographer\": item.get(\"photographer\"),\n",
    "        \"provider\": \"pexels\",\n",
    "        \"license\": \"pexels\",\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def normalize_video_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    files = item.get(\"video_files\", []) or []\n",
    "    chosen = None\n",
    "    if files:\n",
    "        files_sorted = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)\n",
    "        chosen = files_sorted[0]\n",
    "    return {\n",
    "        \"id\": f\"video_{item.get('id')}\",\n",
    "        \"type\": \"video\",\n",
    "        \"url\": chosen.get(\"link\") if chosen else (item.get(\"url\")),\n",
    "        \"duration\": item.get(\"duration\"),\n",
    "        \"width\": chosen.get(\"width\") if chosen else None,\n",
    "        \"height\": chosen.get(\"height\") if chosen else None,\n",
    "        \"provider\": \"pexels\",\n",
    "        \"license\": \"pexels\",\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def fetch_pexels_for_query(query: str, top_k_v: int = MAX_VIDEOS_PER_QUERY, top_k_i: int = MAX_IMAGES_PER_QUERY) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    results = {\"videos\": [], \"images\": []}\n",
    "    try:\n",
    "        vresp = pexels_search_videos(query, per_page=top_k_v)\n",
    "        videos = vresp.get(\"videos\", [])\n",
    "        for v in videos[:top_k_v]:\n",
    "            norm = normalize_video_item(v)\n",
    "            results[\"videos\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] video search failed for query '{query}': {e}\")\n",
    "    try:\n",
    "        presp = pexels_search_photos(query, per_page=top_k_i)\n",
    "        photos = presp.get(\"photos\", [])\n",
    "        for p in photos[:top_k_i]:\n",
    "            norm = normalize_photo_item(p)\n",
    "            results[\"images\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] photo search failed for query '{query}': {e}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ac7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 4) Freesound API helpers (audio)\n",
    "# ---------------------\n",
    "def freesound_search(query: str, page_size: int = MAX_AUDIOS_PER_QUERY) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search Freesound using text search.\n",
    "    Returns the parsed JSON results (the 'results' list contains items).\n",
    "    \"\"\"\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def normalize_freesound_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Normalize a Freesound search result to our asset dict.\n",
    "    We'll prefer the high-quality preview URL for prototyping (preview-hq-mp3 or preview-hq-ogg)\n",
    "    \"\"\"\n",
    "    previews = item.get(\"previews\", {}) or {}\n",
    "    preview_url = previews.get(\"preview-hq-mp3\") or previews.get(\"preview-hq-ogg\") or previews.get(\"preview-lq-mp3\")\n",
    "    return {\n",
    "        \"id\": f\"audio_fs_{item.get('id')}\",\n",
    "        \"type\": \"audio\",\n",
    "        \"url\": preview_url,\n",
    "        \"duration\": item.get(\"duration\"),\n",
    "        \"title\": item.get(\"name\"),\n",
    "        \"uploader\": item.get(\"username\"),\n",
    "        \"tags\": item.get(\"tags\", []),\n",
    "        \"provider\": \"freesound\",\n",
    "        \"license\": item.get(\"license\"),\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def fetch_freesound_for_query(query: str, top_k: int = MAX_AUDIOS_PER_QUERY) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    results = {\"audios\": []}\n",
    "    try:\n",
    "        resp = freesound_search(query, page_size=top_k)\n",
    "        for item in resp.get(\"results\", [])[:top_k]:\n",
    "            norm = normalize_freesound_item(item)\n",
    "            # only include if preview URL exists\n",
    "            if norm.get(\"url\"):\n",
    "                results[\"audios\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] Freesound search failed for query '{query}': {e}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_face_cascade = None\n",
    "def _get_face_cascade():\n",
    "    global _face_cascade\n",
    "    if _face_cascade is None:\n",
    "        cascade_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "        _face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    return _face_cascade\n",
    "\n",
    "def download_bytes(url: str, max_bytes: Optional[int] = None, timeout: int = 12) -> Optional[bytes]:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        if max_bytes:\n",
    "            r = requests.get(url, stream=True, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            buf = io.BytesIO()\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if not chunk:\n",
    "                    break\n",
    "                buf.write(chunk)\n",
    "                if buf.tell() >= max_bytes:\n",
    "                    break\n",
    "            return buf.getvalue()\n",
    "        else:\n",
    "            r = requests.get(url, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            return r.content\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def sample_frames_from_video(url_or_path: str, n_frames: int = 6) -> List[np.ndarray]:\n",
    "    cap = cv2.VideoCapture(url_or_path)\n",
    "    if not cap.isOpened():\n",
    "        try:\n",
    "            data = download_bytes(url_or_path)\n",
    "            if not data:\n",
    "                return []\n",
    "            tmp = \"tmp_asset_video.bin\"\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                f.write(data)\n",
    "            cap = cv2.VideoCapture(tmp)\n",
    "            if not cap.isOpened():\n",
    "                return []\n",
    "        except Exception:\n",
    "            return []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if frame_count <= 0:\n",
    "        frames = []\n",
    "        for _ in range(n_frames):\n",
    "            ret, f = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "        cap.release()\n",
    "        return frames\n",
    "    indices = np.linspace(0, max(0, frame_count - 1), num=min(n_frames, frame_count), dtype=int)\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, f = cap.read()\n",
    "        if not ret or f is None:\n",
    "            continue\n",
    "        frames.append(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def sample_frames_from_image(url_or_path: str) -> List[np.ndarray]:\n",
    "    b = download_bytes(url_or_path)\n",
    "    if not b:\n",
    "        return []\n",
    "    try:\n",
    "        im = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "        arr = np.array(im)\n",
    "        return [arr]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def dominant_colors_from_rgb_array(arr: np.ndarray, top_k: int = 3) -> List[str]:\n",
    "    try:\n",
    "        im = Image.fromarray(arr)\n",
    "        small = im.resize((200, 200))\n",
    "        pal = small.convert(\"P\", palette=Image.ADAPTIVE, colors=top_k)\n",
    "        palette = pal.getpalette()\n",
    "        color_counts = pal.getcolors()\n",
    "        color_counts.sort(reverse=True)\n",
    "        dominant = []\n",
    "        for count, idx in color_counts[:top_k]:\n",
    "            r = palette[idx*3]; g = palette[idx*3+1]; b = palette[idx*3+2]\n",
    "            dominant.append('#{:02x}{:02x}{:02x}'.format(r,g,b))\n",
    "        return dominant\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def compute_motion_intensity(frames: List[np.ndarray]) -> (str, float):\n",
    "    if not frames or len(frames) < 2:\n",
    "        return (\"none\", 0.0)\n",
    "    mags = []\n",
    "    for i in range(1, len(frames)):\n",
    "        a = cv2.cvtColor(frames[i-1], cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
    "        b = cv2.cvtColor(frames[i], cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
    "        diff = np.abs(b - a)\n",
    "        mags.append(diff.mean())\n",
    "    mean_mag = float(np.mean(mags)) if mags else 0.0\n",
    "    if mean_mag < 2.5:\n",
    "        band = \"low\"\n",
    "    elif mean_mag < 8.0:\n",
    "        band = \"medium\"\n",
    "    else:\n",
    "        band = \"high\"\n",
    "    return (band, mean_mag)\n",
    "\n",
    "def estimate_camera_move(frames: List[np.ndarray]) -> (str, float):\n",
    "    if not frames or len(frames) < 2:\n",
    "        return (\"unknown\", 0.0)\n",
    "    try:\n",
    "        prev = cv2.cvtColor(frames[0], cv2.COLOR_RGB2GRAY)\n",
    "        nxt = cv2.cvtColor(frames[-1], cv2.COLOR_RGB2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev, nxt, None,\n",
    "                                            pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        avg_mag = float(np.mean(mag))\n",
    "        avg_dx = float(np.mean(flow[...,0]))\n",
    "        avg_dy = float(np.mean(flow[...,1]))\n",
    "        if avg_mag < 0.5:\n",
    "            return (\"static\", avg_mag)\n",
    "        if abs(avg_dx) > abs(avg_dy) * 1.2:\n",
    "            return (\"pan\", avg_mag)\n",
    "        if abs(avg_dy) > abs(avg_dx) * 1.2:\n",
    "            return (\"tilt\", avg_mag)\n",
    "        return (\"dolly_or_forward\", avg_mag)\n",
    "    except Exception:\n",
    "        return (\"unknown\", 0.0)\n",
    "\n",
    "# YOLO wrapper\n",
    "_yolo_model = None\n",
    "def _get_yolo_model():\n",
    "    global _yolo_model\n",
    "    if not _YOLO_AVAILABLE:\n",
    "        return None\n",
    "    if _yolo_model is None:\n",
    "        _yolo_model = YOLO(\"yolov8n.pt\")\n",
    "    return _yolo_model\n",
    "\n",
    "def detect_with_yolo_on_frames(frames: List[np.ndarray]) -> Dict[str, Any]:\n",
    "    model = _get_yolo_model()\n",
    "    if model is None or not frames:\n",
    "        return {\"objects\": [], \"contains_people\": False, \"person_count\": 0}\n",
    "    try:\n",
    "        frame = frames[0]\n",
    "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)\n",
    "        dets = []\n",
    "        contains_people = False\n",
    "        person_count = 0\n",
    "        if results and len(results) > 0:\n",
    "            r = results[0]\n",
    "            boxes = getattr(r, \"boxes\", []) or []\n",
    "            for b in boxes:\n",
    "                try:\n",
    "                    cls = int(b.cls.cpu().numpy()[0]) if hasattr(b, 'cls') else int(b.cls[0])\n",
    "                    label = model.names.get(cls, str(cls)) if hasattr(model, \"names\") else str(cls)\n",
    "                    conf = float(b.conf.cpu().numpy()[0]) if hasattr(b, 'conf') else float(b.conf[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "                dets.append({\"label\": label, \"conf\": conf})\n",
    "                if label.lower() in (\"person\", \"people\"):\n",
    "                    contains_people = True\n",
    "                    person_count += 1\n",
    "        return {\"objects\": dets, \"contains_people\": contains_people, \"person_count\": person_count}\n",
    "    except Exception:\n",
    "        return {\"objects\": [], \"contains_people\": False, \"person_count\": 0}\n",
    "\n",
    "def detect_faces_on_frames(frames: List[np.ndarray]) -> Dict[str, Any]:\n",
    "    face_cascade = _get_face_cascade()\n",
    "    if face_cascade is None or not frames:\n",
    "        return {\"contains_people\": False, \"person_count\": 0, \"objects\": []}\n",
    "    count = 0\n",
    "    for frame in frames:\n",
    "        try:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30,30))\n",
    "            count += len(faces)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return {\"contains_people\": (count > 0), \"person_count\": count, \"objects\": []}\n",
    "\n",
    "def infer_mood_tags(dominant_colors: List[str], motion_band: str, contains_people: bool, objects: List[Dict]) -> (List[str], float, str):\n",
    "    tags = []; reason_terms = []; temp = 0\n",
    "    if dominant_colors:\n",
    "        def hex_to_rgb(h):\n",
    "            h = h.lstrip('#')\n",
    "            return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "        try:\n",
    "            r,g,b = hex_to_rgb(dominant_colors[0])\n",
    "            temp = (r - b) / 255.0\n",
    "        except Exception:\n",
    "            temp = 0\n",
    "    if motion_band in (\"none\",\"low\"):\n",
    "        if temp > 0.05:\n",
    "            tags.extend([\"calm\", \"nostalgic\"]); reason_terms.append(\"warm_palette+low_motion\")\n",
    "        else:\n",
    "            tags.extend([\"calm\"]); reason_terms.append(\"cool+low_motion\")\n",
    "    elif motion_band == \"medium\":\n",
    "        if temp > 0.05:\n",
    "            tags.extend([\"gentle\", \"pleasant\"]); reason_terms.append(\"warm+medium_motion\")\n",
    "        else:\n",
    "            tags.extend([\"moving\",\"reflective\"]); reason_terms.append(\"cool+medium_motion\")\n",
    "    else:\n",
    "        tags.extend([\"energetic\",\"urgent\"]); reason_terms.append(\"high_motion\")\n",
    "    obj_labels = [o[\"label\"].lower() for o in objects] if objects else []\n",
    "    if contains_people and \"calm\" in tags:\n",
    "        tags.append(\"intimate\"); reason_terms.append(\"people+calm\")\n",
    "    if any(x in obj_labels for x in (\"ocean\",\"beach\",\"shore\",\"wave\",\"sea\",\"kite\")):\n",
    "        if \"calm\" in tags or temp > 0.05:\n",
    "            tags = [\"calm\",\"poignant\"]; reason_terms.append(\"ocean+kite+warm\")\n",
    "    tags = list(dict.fromkeys(tags))[:3]\n",
    "    score = 0.5\n",
    "    if dominant_colors: score += 0.15\n",
    "    if motion_band != \"none\": score += 0.15\n",
    "    if contains_people or objects: score += 0.15\n",
    "    score = min(0.99, score)\n",
    "    reason = \";\".join(reason_terms) if reason_terms else \"\"\n",
    "    return tags, round(score,2), reason\n",
    "\n",
    "def classify_asset(url_or_path: str, asset_type: str = None, sample_frames_count: int = 6) -> Dict[str, Any]:\n",
    "    if asset_type is None:\n",
    "        l = url_or_path.lower()\n",
    "        if any(l.endswith(x) for x in (\".mp4\",\".mov\",\".webm\",\".mkv\",\".avi\")):\n",
    "            asset_type = \"video\"\n",
    "        elif any(l.endswith(x) for x in (\".jpg\",\".jpeg\",\".png\",\".webp\")):\n",
    "            asset_type = \"image\"\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(url_or_path)\n",
    "            if cap and cap.isOpened():\n",
    "                asset_type = \"video\"; cap.release()\n",
    "            else:\n",
    "                asset_type = \"image\"\n",
    "    frames = sample_frames_from_video(url_or_path, n_frames=sample_frames_count) if asset_type==\"video\" else sample_frames_from_image(url_or_path)\n",
    "    classification = {\n",
    "        \"contains_people\": False, \"person_count\": 0, \"objects\": [],\n",
    "        \"motion_intensity\": \"none\", \"motion_metric\": 0.0,\n",
    "        \"camera_move\": \"unknown\", \"camera_move_metric\": 0.0,\n",
    "        \"dominant_colors\": [], \"mood_tags\": [], \"mood_confidence\": 0.0, \"mood_reason\": \"\", \"notes\": \"\"\n",
    "    }\n",
    "    if not frames:\n",
    "        classification[\"notes\"]=\"no_frames_obtained\"\n",
    "        return {\"url\":url_or_path, \"type\":asset_type, \"classification\":classification}\n",
    "    try:\n",
    "        dom = dominant_colors_from_rgb_array(frames[0], top_k=3)\n",
    "        classification[\"dominant_colors\"]=dom\n",
    "    except Exception:\n",
    "        classification[\"dominant_colors\"]=[]\n",
    "    if _YOLO_AVAILABLE:\n",
    "        try:\n",
    "            det = detect_with_yolo_on_frames(frames)\n",
    "            classification[\"objects\"]=det.get(\"objects\",[])\n",
    "            classification[\"contains_people\"]=bool(det.get(\"contains_people\",False))\n",
    "            classification[\"person_count\"]=int(det.get(\"person_count\",0))\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"]+=f\"yolo_failed:{e};\"\n",
    "    else:\n",
    "        try:\n",
    "            det = detect_faces_on_frames(frames)\n",
    "            classification[\"contains_people\"]=det.get(\"contains_people\",False)\n",
    "            classification[\"person_count\"]=det.get(\"person_count\",0)\n",
    "            classification[\"objects\"]=[]\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"]+=f\"face_failed:{e};\"\n",
    "    try:\n",
    "        band, metric = compute_motion_intensity(frames)\n",
    "        classification[\"motion_intensity\"]=band; classification[\"motion_metric\"]=round(metric,3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"motion_failed:{e};\"\n",
    "    try:\n",
    "        cam, cam_metric = estimate_camera_move(frames)\n",
    "        classification[\"camera_move\"]=cam; classification[\"camera_move_metric\"]=round(cam_metric,3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"camera_move_failed:{e};\"\n",
    "    try:\n",
    "        tags, conf, reason = infer_mood_tags(classification[\"dominant_colors\"], classification[\"motion_intensity\"], classification[\"contains_people\"], classification[\"objects\"])\n",
    "        classification[\"mood_tags\"]=tags; classification[\"mood_confidence\"]=conf; classification[\"mood_reason\"]=reason\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"mood_failed:{e};\"\n",
    "    return {\"url\":url_or_path, \"type\":asset_type, \"classification\":classification}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6ec108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Prompt: Calm winds near seashore\n",
      "[DONE] Saved results to assets_unstructured.json\n",
      "Found 20 photos, 15 videos (Pexels), 6 audio previews (Freesound) across 5 queries.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "collect_assets_unstructured.py\n",
    "\n",
    "- Input: a basic user prompt (unstructured).\n",
    "- Uses OpenAI to create 4-6 similar queries (fallback if OpenAI not available).\n",
    "- For each query: searches Pexels (photos + videos) and Freesound (audio).\n",
    "- Saves combined results to assets_unstructured.json.\n",
    "\n",
    "Notes:\n",
    "- Prefer the official APIs (we use them here).\n",
    "- This is intentionally simple and avoids heavy dependencies.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# OpenAI modern client\n",
    "from openai import OpenAI\n",
    "\n",
    "# --------------------------\n",
    "# Config & keys (from .env)\n",
    "# --------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "USE_OPENAI = bool(OPENAI_API_KEY)\n",
    "client = None\n",
    "if USE_OPENAI:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Endpoints & constants\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}\n",
    "\n",
    "# Limits - tune as needed\n",
    "MAX_QUERIES = 6\n",
    "PEXELS_PER_QUERY_PHOTOS = 4\n",
    "PEXELS_PER_QUERY_VIDEOS = 3\n",
    "FREESOUND_PER_QUERY = 3\n",
    "DELAY_BETWEEN_PROVIDER_CALLS = 0.25  # polite delay\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Helper: generate similar queries using OpenAI (or fallback)\n",
    "# --------------------------\n",
    "def generate_queries_via_openai(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Ask OpenAI to return a JSON array of short search queries similar to the prompt.\n",
    "    If OpenAI is not configured or fails, use a conservative fallback.\n",
    "    \"\"\"\n",
    "    if not USE_OPENAI or client is None:\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY a JSON array of short search query strings \"\n",
    "        \"(no explanation). Each string should be concise (1-6 words) and be a close variant or related \"\n",
    "        \"search term that would help find images/videos/audio for the brief. Return exactly the JSON array.\"\n",
    "    )\n",
    "    user = f\"Create {n} concise search queries for this brief: \\\"{prompt}\\\". Return JSON array only.\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        # safe access to message content\n",
    "        try:\n",
    "            content = resp.choices[0].message[\"content\"]\n",
    "        except Exception:\n",
    "            content = resp.choices[0].message.content if hasattr(resp.choices[0].message, \"content\") else \"\"\n",
    "        text = content.strip()\n",
    "        # strip code fences if present\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.splitlines()\n",
    "            if len(lines) >= 3:\n",
    "                text = \"\\n\".join(lines[1:-1])\n",
    "        queries = json.loads(text)\n",
    "        # sanitize and limit\n",
    "        cleaned = []\n",
    "        for q in queries:\n",
    "            if isinstance(q, str):\n",
    "                s = \" \".join(q.split()).strip()\n",
    "                if s:\n",
    "                    cleaned.append(s)\n",
    "            if len(cleaned) >= n:\n",
    "                break\n",
    "        if cleaned:\n",
    "            return cleaned\n",
    "        else:\n",
    "            return fallback_generate_queries(prompt, n)\n",
    "    except Exception as e:\n",
    "        # fallback\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "\n",
    "def fallback_generate_queries(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Conservative deterministic fallback: produce n query variants for the prompt.\n",
    "    \"\"\"\n",
    "    base = prompt.strip()\n",
    "    tokens = [t for t in base.split() if t]\n",
    "    queries = []\n",
    "    # 1: the original brief\n",
    "    queries.append(base)\n",
    "    # 2: add synonyms / context phrases\n",
    "    queries.append(base + \" street scene\")\n",
    "    queries.append(base + \" crowd\")\n",
    "    queries.append(base + \" city life\")\n",
    "    queries.append(base + \" people walking at street\")\n",
    "    # dedupe and limit\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        qn = \" \".join(q.split())\n",
    "        if qn.lower() not in seen:\n",
    "            seen.add(qn.lower())\n",
    "            final.append(qn)\n",
    "        if len(final) >= n:\n",
    "            break\n",
    "    return final\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Pexels API fetch helpers\n",
    "# --------------------------\n",
    "def pexels_search_photos(query: str, per_page: int = PEXELS_PER_QUERY_PHOTOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for p in data.get(\"photos\", [])[:per_page]:\n",
    "            items.append({\n",
    "                \"id\": f\"photo_{p.get('id')}\",\n",
    "                \"url\": p.get(\"src\", {}).get(\"original\") or p.get(\"src\", {}).get(\"large\"),\n",
    "                \"width\": p.get(\"width\"),\n",
    "                \"height\": p.get(\"height\"),\n",
    "                \"photographer\": p.get(\"photographer\"),\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": p\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS PHOTOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = PEXELS_PER_QUERY_VIDEOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for v in data.get(\"videos\", [])[:per_page]:\n",
    "            # pick best file (highest width*fps) if available\n",
    "            files = v.get(\"video_files\", []) or []\n",
    "            chosen = None\n",
    "            if files:\n",
    "                files_sorted = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)\n",
    "                chosen = files_sorted[0]\n",
    "            items.append({\n",
    "                \"id\": f\"video_{v.get('id')}\",\n",
    "                \"url\": (chosen.get(\"link\") if chosen else v.get(\"url\")),\n",
    "                \"duration\": v.get(\"duration\"),\n",
    "                \"width\": chosen.get(\"width\") if chosen else None,\n",
    "                \"height\": chosen.get(\"height\") if chosen else None,\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": v\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS VIDEOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Freesound API fetch helpers\n",
    "# --------------------------\n",
    "def freesound_search(query: str, page_size: int = FREESOUND_PER_QUERY) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    try:\n",
    "        r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for item in data.get(\"results\", [])[:page_size]:\n",
    "            previews = item.get(\"previews\", {}) or {}\n",
    "            preview_url = previews.get(\"preview-hq-mp3\") or previews.get(\"preview-hq-ogg\") or previews.get(\"preview-lq-mp3\")\n",
    "            items.append({\n",
    "                \"id\": f\"fs_{item.get('id')}\",\n",
    "                \"title\": item.get(\"name\"),\n",
    "                \"url\": preview_url,\n",
    "                \"duration\": item.get(\"duration\"),\n",
    "                \"uploader\": item.get(\"username\"),\n",
    "                \"tags\": item.get(\"tags\", []),\n",
    "                \"license\": item.get(\"license\"),\n",
    "                \"provider\": \"freesound\",\n",
    "                \"raw\": item\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[FREESOUND ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main pipeline\n",
    "# --------------------------\n",
    "def collect_assets_for_prompt(prompt: str, num_queries: int = MAX_QUERIES) -> Dict[str, Any]:\n",
    "    out = {\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_queries\": [],\n",
    "        \"results\": {},  # query -> {pexels: {photos:[], videos:[]}, freesound: {audios:[]}}\n",
    "        \"notes\": {}\n",
    "    }\n",
    "\n",
    "    # 1) generate queries\n",
    "    queries = generate_queries_via_openai(prompt, n=num_queries)\n",
    "    out[\"generated_queries\"] = queries\n",
    "\n",
    "    # 2) for each query, fetch from Pexels + Freesound\n",
    "    for q in queries:\n",
    "        qkey = q\n",
    "        out[\"results\"][qkey] = {\"pexels\": {\"photos\": [], \"videos\": []}, \"freesound\": {\"audios\": []}}\n",
    "        # Pexels photos\n",
    "        photos = pexels_search_photos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        videos = pexels_search_videos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        audios = freesound_search(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        out[\"results\"][qkey][\"pexels\"][\"photos\"] = photos\n",
    "        out[\"results\"][qkey][\"pexels\"][\"videos\"] = videos\n",
    "        out[\"results\"][qkey][\"freesound\"][\"audios\"] = audios\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLI / example usage\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Collect Pexels + Freesound assets for an unstructured prompt.\")\n",
    "    parser.add_argument(\"--prompt\", \"-p\", type=str, help=\"User prompt (e.g. 'bustling city with people')\", required=False)\n",
    "    parser.add_argument(\"--queries\", \"-q\", type=int, default=5, help=\"Number of similar queries to generate (default 5)\")\n",
    "    parser.add_argument(\"--out\", \"-o\", type=str, default=\"assets_unstructured.json\", help=\"Output JSON filename\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if not args.prompt:\n",
    "        # interactive ask\n",
    "        user_prompt = input(\"Enter a prompt (e.g. 'bustling city with people'): \").strip()\n",
    "    else:\n",
    "        user_prompt = args.prompt.strip()\n",
    "\n",
    "    print(\"[RUN] Prompt:\", user_prompt)\n",
    "    plan = collect_assets_for_prompt(user_prompt, num_queries=args.queries)\n",
    "\n",
    "    # save output\n",
    "    with open(args.out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(plan, f, indent=2)\n",
    "\n",
    "    print(f\"[DONE] Saved results to {args.out}\")\n",
    "    # print summary\n",
    "    total_photos = sum(len(plan[\"results\"][q][\"pexels\"][\"photos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_videos = sum(len(plan[\"results\"][q][\"pexels\"][\"videos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_audios = sum(len(plan[\"results\"][q][\"freesound\"][\"audios\"]) for q in plan[\"generated_queries\"])\n",
    "    print(f\"Found {total_photos} photos, {total_videos} videos (Pexels), {total_audios} audio previews (Freesound) across {len(plan['generated_queries'])} queries.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
