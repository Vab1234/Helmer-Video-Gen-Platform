{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92beca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.107.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests python-dotenv openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5611b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Prompt: lady sipping coffee in cafe\n",
      "[DONE] Saved results to assets_unstructured.json\n",
      "Found 20 photos, 15 videos (Pexels), 2 audio previews (Freesound) across 5 queries.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "collect_assets_unstructured.py\n",
    "\n",
    "- Input: a basic user prompt (unstructured).\n",
    "- Uses OpenAI to create 4-6 similar queries (fallback if OpenAI not available).\n",
    "- For each query: searches Pexels (photos + videos) and Freesound (audio).\n",
    "- Saves combined results to assets_unstructured.json.\n",
    "\n",
    "Notes:\n",
    "- Prefer the official APIs (we use them here).\n",
    "- This is intentionally simple and avoids heavy dependencies.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# OpenAI modern client\n",
    "from openai import OpenAI\n",
    "\n",
    "# --------------------------\n",
    "# Config & keys (from .env)\n",
    "# --------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "USE_OPENAI = bool(OPENAI_API_KEY)\n",
    "client = None\n",
    "if USE_OPENAI:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Endpoints & constants\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}\n",
    "\n",
    "# Limits - tune as needed\n",
    "MAX_QUERIES = 6\n",
    "PEXELS_PER_QUERY_PHOTOS = 4\n",
    "PEXELS_PER_QUERY_VIDEOS = 3\n",
    "FREESOUND_PER_QUERY = 3\n",
    "DELAY_BETWEEN_PROVIDER_CALLS = 0.25  # polite delay\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Helper: generate similar queries using OpenAI (or fallback)\n",
    "# --------------------------\n",
    "def generate_queries_via_openai(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Ask OpenAI to return a JSON array of short search queries similar to the prompt.\n",
    "    If OpenAI is not configured or fails, use a conservative fallback.\n",
    "    \"\"\"\n",
    "    if not USE_OPENAI or client is None:\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY a JSON array of short search query strings \"\n",
    "        \"(no explanation). Each string should be concise (1-6 words) and be a close variant or related \"\n",
    "        \"search term that would help find images/videos/audio for the brief. Return exactly the JSON array.\"\n",
    "    )\n",
    "    user = f\"Create {n} concise search queries for this brief: \\\"{prompt}\\\". Return JSON array only.\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        # safe access to message content\n",
    "        try:\n",
    "            content = resp.choices[0].message[\"content\"]\n",
    "        except Exception:\n",
    "            content = resp.choices[0].message.content if hasattr(resp.choices[0].message, \"content\") else \"\"\n",
    "        text = content.strip()\n",
    "        # strip code fences if present\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.splitlines()\n",
    "            if len(lines) >= 3:\n",
    "                text = \"\\n\".join(lines[1:-1])\n",
    "        queries = json.loads(text)\n",
    "        # sanitize and limit\n",
    "        cleaned = []\n",
    "        for q in queries:\n",
    "            if isinstance(q, str):\n",
    "                s = \" \".join(q.split()).strip()\n",
    "                if s:\n",
    "                    cleaned.append(s)\n",
    "            if len(cleaned) >= n:\n",
    "                break\n",
    "        if cleaned:\n",
    "            return cleaned\n",
    "        else:\n",
    "            return fallback_generate_queries(prompt, n)\n",
    "    except Exception as e:\n",
    "        # fallback\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "\n",
    "def fallback_generate_queries(prompt: str, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Conservative deterministic fallback: produce n query variants for the prompt.\n",
    "    \"\"\"\n",
    "    base = prompt.strip()\n",
    "    tokens = [t for t in base.split() if t]\n",
    "    queries = []\n",
    "    # 1: the original brief\n",
    "    queries.append(base)\n",
    "    # 2: add synonyms / context phrases\n",
    "    queries.append(base + \" street scene\")\n",
    "    queries.append(base + \" crowd\")\n",
    "    queries.append(base + \" city life\")\n",
    "    queries.append(base + \" people walking at street\")\n",
    "    # dedupe and limit\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        qn = \" \".join(q.split())\n",
    "        if qn.lower() not in seen:\n",
    "            seen.add(qn.lower())\n",
    "            final.append(qn)\n",
    "        if len(final) >= n:\n",
    "            break\n",
    "    return final\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Pexels API fetch helpers\n",
    "# --------------------------\n",
    "def pexels_search_photos(query: str, per_page: int = PEXELS_PER_QUERY_PHOTOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for p in data.get(\"photos\", [])[:per_page]:\n",
    "            items.append({\n",
    "                \"id\": f\"photo_{p.get('id')}\",\n",
    "                \"url\": p.get(\"src\", {}).get(\"original\") or p.get(\"src\", {}).get(\"large\"),\n",
    "                \"width\": p.get(\"width\"),\n",
    "                \"height\": p.get(\"height\"),\n",
    "                \"photographer\": p.get(\"photographer\"),\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": p\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS PHOTOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = PEXELS_PER_QUERY_VIDEOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for v in data.get(\"videos\", [])[:per_page]:\n",
    "            # pick best file (highest width*fps) if available\n",
    "            files = v.get(\"video_files\", []) or []\n",
    "            chosen = None\n",
    "            if files:\n",
    "                files_sorted = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)\n",
    "                chosen = files_sorted[0]\n",
    "            items.append({\n",
    "                \"id\": f\"video_{v.get('id')}\",\n",
    "                \"url\": (chosen.get(\"link\") if chosen else v.get(\"url\")),\n",
    "                \"duration\": v.get(\"duration\"),\n",
    "                \"width\": chosen.get(\"width\") if chosen else None,\n",
    "                \"height\": chosen.get(\"height\") if chosen else None,\n",
    "                \"provider\": \"pexels\",\n",
    "                \"raw\": v\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS VIDEOS ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Freesound API fetch helpers\n",
    "# --------------------------\n",
    "def freesound_search(query: str, page_size: int = FREESOUND_PER_QUERY) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    try:\n",
    "        r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = []\n",
    "        for item in data.get(\"results\", [])[:page_size]:\n",
    "            previews = item.get(\"previews\", {}) or {}\n",
    "            preview_url = previews.get(\"preview-hq-mp3\") or previews.get(\"preview-hq-ogg\") or previews.get(\"preview-lq-mp3\")\n",
    "            items.append({\n",
    "                \"id\": f\"fs_{item.get('id')}\",\n",
    "                \"title\": item.get(\"name\"),\n",
    "                \"url\": preview_url,\n",
    "                \"duration\": item.get(\"duration\"),\n",
    "                \"uploader\": item.get(\"username\"),\n",
    "                \"tags\": item.get(\"tags\", []),\n",
    "                \"license\": item.get(\"license\"),\n",
    "                \"provider\": \"freesound\",\n",
    "                \"raw\": item\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[FREESOUND ERROR] query='{query}' -> {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main pipeline\n",
    "# --------------------------\n",
    "def collect_assets_for_prompt(prompt: str, num_queries: int = MAX_QUERIES) -> Dict[str, Any]:\n",
    "    out = {\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_queries\": [],\n",
    "        \"results\": {},  # query -> {pexels: {photos:[], videos:[]}, freesound: {audios:[]}}\n",
    "        \"notes\": {}\n",
    "    }\n",
    "\n",
    "    # 1) generate queries\n",
    "    queries = generate_queries_via_openai(prompt, n=num_queries)\n",
    "    out[\"generated_queries\"] = queries\n",
    "\n",
    "    # 2) for each query, fetch from Pexels + Freesound\n",
    "    for q in queries:\n",
    "        qkey = q\n",
    "        out[\"results\"][qkey] = {\"pexels\": {\"photos\": [], \"videos\": []}, \"freesound\": {\"audios\": []}}\n",
    "        # Pexels photos\n",
    "        photos = pexels_search_photos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        videos = pexels_search_videos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        audios = freesound_search(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        out[\"results\"][qkey][\"pexels\"][\"photos\"] = photos\n",
    "        out[\"results\"][qkey][\"pexels\"][\"videos\"] = videos\n",
    "        out[\"results\"][qkey][\"freesound\"][\"audios\"] = audios\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLI / example usage\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Collect Pexels + Freesound assets for an unstructured prompt.\")\n",
    "    parser.add_argument(\"--prompt\", \"-p\", type=str, help=\"User prompt (e.g. 'bustling city with people')\", required=False)\n",
    "    parser.add_argument(\"--queries\", \"-q\", type=int, default=5, help=\"Number of similar queries to generate (default 5)\")\n",
    "    parser.add_argument(\"--out\", \"-o\", type=str, default=\"assets_unstructured.json\", help=\"Output JSON filename\")\n",
    "    args,unknown = parser.parse_known_args()\n",
    "\n",
    "    if not args.prompt:\n",
    "        # interactive ask\n",
    "        user_prompt = input(\"Enter a prompt (e.g. 'bustling city with people'): \").strip()\n",
    "    else:\n",
    "        user_prompt = args.prompt.strip()\n",
    "\n",
    "    print(\"[RUN] Prompt:\", user_prompt)\n",
    "    plan = collect_assets_for_prompt(user_prompt, num_queries=args.queries)\n",
    "\n",
    "    # save output\n",
    "    with open(args.out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(plan, f, indent=2)\n",
    "\n",
    "    print(f\"[DONE] Saved results to {args.out}\")\n",
    "    # print summary\n",
    "    total_photos = sum(len(plan[\"results\"][q][\"pexels\"][\"photos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_videos = sum(len(plan[\"results\"][q][\"pexels\"][\"videos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_audios = sum(len(plan[\"results\"][q][\"freesound\"][\"audios\"]) for q in plan[\"generated_queries\"])\n",
    "    print(f\"Found {total_photos} photos, {total_videos} videos (Pexels), {total_audios} audio previews (Freesound) across {len(plan['generated_queries'])} queries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff0fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Prompt: a cat walking on a wall and looking for a mouse\n",
      "[DONE] Saved results to assets_with_mood.json\n",
      "Found 20 photos, 15 videos, 0 audios across 5 queries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# --------------------------\n",
    "# Config & keys (from .env)\n",
    "# --------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "USE_OPENAI = bool(OPENAI_API_KEY)\n",
    "client = OpenAI(api_key=OPENAI_API_KEY) if USE_OPENAI else None\n",
    "\n",
    "# Endpoints & constants\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}\n",
    "\n",
    "MAX_QUERIES = 6\n",
    "PEXELS_PER_QUERY_PHOTOS = 4\n",
    "PEXELS_PER_QUERY_VIDEOS = 3\n",
    "FREESOUND_PER_QUERY = 3\n",
    "DELAY_BETWEEN_PROVIDER_CALLS = 0.25\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Mood Detection\n",
    "# --------------------------\n",
    "def detect_mood(text: str) -> str:\n",
    "    \"\"\"Use OpenAI to detect mood of a text. Fallback -> Neutral.\"\"\"\n",
    "    if not USE_OPENAI or client is None:\n",
    "        return \"Neutral\"\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following text and return the overall mood/tone\n",
    "        in one or two words only (examples: Hopeful, Urgent, Alarming, Inspirational, Calm, Excited).\n",
    "\n",
    "        Text: \"{text}\"\n",
    "        \"\"\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a mood detection assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        mood = resp.choices[0].message.content.strip()\n",
    "        return mood if mood else \"Neutral\"\n",
    "    except Exception:\n",
    "        return \"Neutral\"\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Generate queries (OpenAI + fallback)\n",
    "# --------------------------\n",
    "def generate_queries_via_openai(prompt: str, n: int = 5) -> List[str]:\n",
    "    if not USE_OPENAI or client is None:\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY a JSON array of short search query strings \"\n",
    "        \"(no explanation). Each string should be concise (1-6 words).\"\n",
    "    )\n",
    "    user = f\"Create {n} concise search queries for this brief: \\\"{prompt}\\\". Return JSON array only.\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=[{\"role\": \"system\", \"content\": system},\n",
    "                      {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.splitlines()\n",
    "            if len(lines) >= 3:\n",
    "                text = \"\\n\".join(lines[1:-1])\n",
    "        queries = json.loads(text)\n",
    "        return [q.strip() for q in queries if isinstance(q, str)][:n]\n",
    "    except Exception:\n",
    "        return fallback_generate_queries(prompt, n)\n",
    "\n",
    "\n",
    "def fallback_generate_queries(prompt: str, n: int = 5) -> List[str]:\n",
    "    base = prompt.strip()\n",
    "    queries = [\n",
    "        base,\n",
    "        base + \" street scene\",\n",
    "        base + \" crowd\",\n",
    "        base + \" city life\",\n",
    "        base + \" people walking at street\",\n",
    "    ]\n",
    "    return queries[:n]\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Pexels + Freesound search\n",
    "# --------------------------\n",
    "def pexels_search_photos(query: str, per_page: int = PEXELS_PER_QUERY_PHOTOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        return [{\n",
    "            \"id\": f\"photo_{p['id']}\",\n",
    "            \"url\": p.get(\"src\", {}).get(\"original\") or p.get(\"src\", {}).get(\"large\"),\n",
    "            \"width\": p.get(\"width\"),\n",
    "            \"height\": p.get(\"height\"),\n",
    "            \"photographer\": p.get(\"photographer\"),\n",
    "            \"provider\": \"pexels\"\n",
    "        } for p in r.json().get(\"photos\", [])[:per_page]]\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS PHOTOS ERROR] {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = PEXELS_PER_QUERY_VIDEOS) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    try:\n",
    "        r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        items = []\n",
    "        for v in r.json().get(\"videos\", [])[:per_page]:\n",
    "            files = v.get(\"video_files\", [])\n",
    "            chosen = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)[0] if files else None\n",
    "            items.append({\n",
    "                \"id\": f\"video_{v['id']}\",\n",
    "                \"url\": chosen.get(\"link\") if chosen else v.get(\"url\"),\n",
    "                \"duration\": v.get(\"duration\"),\n",
    "                \"width\": chosen.get(\"width\") if chosen else None,\n",
    "                \"height\": chosen.get(\"height\") if chosen else None,\n",
    "                \"provider\": \"pexels\"\n",
    "            })\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[PEXELS VIDEOS ERROR] {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def freesound_search(query: str, page_size: int = FREESOUND_PER_QUERY) -> List[Dict[str, Any]]:\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    try:\n",
    "        r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "        r.raise_for_status()\n",
    "        return [{\n",
    "            \"id\": f\"fs_{item['id']}\",\n",
    "            \"title\": item[\"name\"],\n",
    "            \"url\": item.get(\"previews\", {}).get(\"preview-hq-mp3\"),\n",
    "            \"duration\": item[\"duration\"],\n",
    "            \"uploader\": item[\"username\"],\n",
    "            \"tags\": item.get(\"tags\", []),\n",
    "            \"license\": item[\"license\"],\n",
    "            \"provider\": \"freesound\"\n",
    "        } for item in r.json().get(\"results\", [])[:page_size]]\n",
    "    except Exception as e:\n",
    "        print(f\"[FREESOUND ERROR] {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main pipeline\n",
    "# --------------------------\n",
    "def collect_assets_for_prompt(prompt: str, num_queries: int = MAX_QUERIES) -> Dict[str, Any]:\n",
    "    out = {\n",
    "        \"prompt\": prompt,\n",
    "        \"global_mood\": detect_mood(prompt),\n",
    "        \"generated_queries\": [],\n",
    "        \"results\": {}\n",
    "    }\n",
    "\n",
    "    queries = generate_queries_via_openai(prompt, n=num_queries)\n",
    "    out[\"generated_queries\"] = queries\n",
    "\n",
    "    for q in queries:\n",
    "        out[\"results\"][q] = {\n",
    "            \"query_mood\": detect_mood(q),\n",
    "            \"pexels\": {\"photos\": [], \"videos\": []},\n",
    "            \"freesound\": {\"audios\": []}\n",
    "        }\n",
    "        out[\"results\"][q][\"pexels\"][\"photos\"] = pexels_search_photos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        out[\"results\"][q][\"pexels\"][\"videos\"] = pexels_search_videos(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "        out[\"results\"][q][\"freesound\"][\"audios\"] = freesound_search(q)\n",
    "        time.sleep(DELAY_BETWEEN_PROVIDER_CALLS)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLI / example usage\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description=\"Collect Pexels + Freesound assets with mood detection.\")\n",
    "    parser.add_argument(\"--prompt\", \"-p\", type=str, help=\"User prompt\", required=False)\n",
    "    parser.add_argument(\"--queries\", \"-q\", type=int, default=5, help=\"Number of queries\")\n",
    "    parser.add_argument(\"--out\", \"-o\", type=str, default=\"assets_with_mood.json\", help=\"Output JSON filename\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    user_prompt = args.prompt.strip() if args.prompt else input(\"Enter a prompt: \").strip()\n",
    "\n",
    "    print(\"[RUN] Prompt:\", user_prompt)\n",
    "    plan = collect_assets_for_prompt(user_prompt, num_queries=args.queries)\n",
    "\n",
    "    with open(args.out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(plan, f, indent=2)\n",
    "\n",
    "    print(f\"[DONE] Saved results to {args.out}\")\n",
    "    total_photos = sum(len(plan[\"results\"][q][\"pexels\"][\"photos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_videos = sum(len(plan[\"results\"][q][\"pexels\"][\"videos\"]) for q in plan[\"generated_queries\"])\n",
    "    total_audios = sum(len(plan[\"results\"][q][\"freesound\"][\"audios\"]) for q in plan[\"generated_queries\"])\n",
    "    print(f\"Found {total_photos} photos, {total_videos} videos, {total_audios} audios across {len(plan['generated_queries'])} queries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1575815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
