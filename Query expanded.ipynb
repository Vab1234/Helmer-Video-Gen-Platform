{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92beca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JENNIFER\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34e7068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.107.3)\n",
      "Requirement already satisfied: selenium in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai selenium webdriver-manager python-dotenv beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d20e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.3.193)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.15.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.33.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless pillow numpy requests python-dotenv\n",
    "# optional (better object detection): ultralytics (YOLOv8)\n",
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfa1045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mutagen in c:\\users\\jennifer\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.47.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mutagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f861ab",
   "metadata": {},
   "source": [
    "plan_pexels_enriched_with_audio.py\n",
    "\n",
    "- Uses OpenAI to split a brief into structured shots\n",
    "- Uses Pexels API to fetch videos & images for each shot\n",
    "- Uses Freesound API to fetch audio previews matching queries\n",
    "- Classifies discovered assets (image/video/audio) with lightweight heuristics\n",
    "- Produces plan_pexels_enriched_with_audio.json (shots + asset_manifest with classification)\n",
    "\n",
    "Requirements:\n",
    "- Put OPENAI_API_KEY, PEXELS_API_KEY, FREESOUND_API_KEY in a .env file or environment.\n",
    "- pip install openai requests python-dotenv pillow opencv-python-headless numpy ultralytics mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61acf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from typing import List, Dict, Any, Optional\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mutagen import File as MutagenFile  # for audio metadata\n",
    "\n",
    "# --- OpenAI modern client ---\n",
    "from openai import OpenAI\n",
    "\n",
    "# Try to import ultralytics YOLO (optional)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    _YOLO_AVAILABLE = True\n",
    "except Exception:\n",
    "    _YOLO_AVAILABLE = False\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "FREESOUND_API_KEY = os.getenv(\"FREESOUND_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"Please set OPENAI_API_KEY in your environment or .env file\")\n",
    "if not PEXELS_API_KEY:\n",
    "    raise RuntimeError(\"Please set PEXELS_API_KEY in your environment or .env file\")\n",
    "if not FREESOUND_API_KEY:\n",
    "    raise RuntimeError(\"Please set FREESOUND_API_KEY in your environment or .env file\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # change if you prefer another model\n",
    "\n",
    "# Pexels API endpoints\n",
    "PEXELS_PHOTO_SEARCH = \"https://api.pexels.com/v1/search\"\n",
    "PEXELS_VIDEO_SEARCH = \"https://api.pexels.com/videos/search\"\n",
    "PEXELS_HEADERS = {\"Authorization\": PEXELS_API_KEY}\n",
    "\n",
    "# Freesound endpoints\n",
    "FREESOUND_SEARCH = \"https://freesound.org/apiv2/search/text/\"\n",
    "FREESOUND_HEADERS = {\"Authorization\": f\"Token {FREESOUND_API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VIDEOS_PER_QUERY = 3\n",
    "MAX_IMAGES_PER_QUERY = 3\n",
    "MAX_AUDIOS_PER_QUERY = 3\n",
    "MAX_QUERIES_PER_SHOT = 3\n",
    "MAX_SHOTS = 6\n",
    "\n",
    "# ---------------------\n",
    "# 1) OpenAI shot-splitting (structured JSON)\n",
    "# ---------------------\n",
    "def ask_model_for_shots(prompt_text: str, min_shots: int = 1, max_shots: int = 4) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Use OpenAI to return structured shots JSON (id, text_description, suggested_duration_seconds, keywords, style_tokens, negative_filters)\n",
    "    \"\"\"\n",
    "    system = (\n",
    "        \"You are an assistant that MUST return ONLY valid JSON (no commentary). \"\n",
    "        f\"Given a short video brief, return an array of between {min_shots} and {max_shots} shots. \"\n",
    "        \"Each shot object must include the following keys: \"\n",
    "        '\"id\" (string), \"text_description\" (string), \"suggested_duration_seconds\" (integer), '\n",
    "        '\"keywords\" (array of strings), \"style_tokens\" (array of strings), \"negative_filters\" (array of strings).'\n",
    "    )\n",
    "    user = f\"Convert this brief into shots: \\\"{prompt_text}\\\". Return JSON only.\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=400,\n",
    "    )\n",
    "\n",
    "    # safe access to content\n",
    "    try:\n",
    "        content = resp.choices[0].message[\"content\"]\n",
    "    except Exception:\n",
    "        try:\n",
    "            content = resp.choices[0].message.content\n",
    "        except Exception:\n",
    "            content = resp.choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "    text = content.strip() if content else \"\"\n",
    "    # strip backticks if model wraps JSON in fences\n",
    "    if text.startswith(\"```\"):\n",
    "        lines = text.splitlines()\n",
    "        if len(lines) >= 3:\n",
    "            text = \"\\n\".join(lines[1:-1])\n",
    "\n",
    "    try:\n",
    "        shots = json.loads(text)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to parse JSON from model output: {e}\\n---\\n{text}\")\n",
    "\n",
    "    if not isinstance(shots, list):\n",
    "        raise RuntimeError(\"Model did not return a JSON array of shots.\")\n",
    "    return shots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bced91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 2) Query expansion\n",
    "# ---------------------\n",
    "def expand_queries_for_shot(shot: Dict[str, Any], max_queries: int = MAX_QUERIES_PER_SHOT) -> List[str]:\n",
    "    queries = []\n",
    "    text = shot.get(\"text_description\", \"\").strip()\n",
    "    if text:\n",
    "        queries.append(text)\n",
    "    keywords = shot.get(\"keywords\", []) or []\n",
    "    if keywords:\n",
    "        queries.append(\" \".join(keywords))\n",
    "        for k in keywords[:2]:\n",
    "            queries.append(k)\n",
    "    style_tokens = shot.get(\"style_tokens\", []) or []\n",
    "    if style_tokens and text:\n",
    "        queries.append(text + \" \" + \" \".join(style_tokens[:2]))\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for q in queries:\n",
    "        qclean = \" \".join(q.split())\n",
    "        if qclean and qclean not in seen:\n",
    "            seen.add(qclean)\n",
    "            final.append(qclean)\n",
    "        if len(final) >= max_queries:\n",
    "            break\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49a1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 3) Pexels API helpers (fetch)\n",
    "# ---------------------\n",
    "def pexels_search_photos(query: str, per_page: int = MAX_IMAGES_PER_QUERY) -> Dict[str, Any]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    r = requests.get(PEXELS_PHOTO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def pexels_search_videos(query: str, per_page: int = MAX_VIDEOS_PER_QUERY) -> Dict[str, Any]:\n",
    "    params = {\"query\": query, \"per_page\": per_page}\n",
    "    r = requests.get(PEXELS_VIDEO_SEARCH, headers=PEXELS_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def normalize_photo_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"id\": f\"photo_{item.get('id')}\",\n",
    "        \"type\": \"image\",\n",
    "        \"url\": item.get(\"src\", {}).get(\"original\") or item.get(\"src\", {}).get(\"large\"),\n",
    "        \"width\": item.get(\"width\"),\n",
    "        \"height\": item.get(\"height\"),\n",
    "        \"photographer\": item.get(\"photographer\"),\n",
    "        \"provider\": \"pexels\",\n",
    "        \"license\": \"pexels\",\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def normalize_video_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    files = item.get(\"video_files\", []) or []\n",
    "    chosen = None\n",
    "    if files:\n",
    "        files_sorted = sorted(files, key=lambda f: (f.get(\"width\", 0), f.get(\"fps\", 0)), reverse=True)\n",
    "        chosen = files_sorted[0]\n",
    "    return {\n",
    "        \"id\": f\"video_{item.get('id')}\",\n",
    "        \"type\": \"video\",\n",
    "        \"url\": chosen.get(\"link\") if chosen else (item.get(\"url\")),\n",
    "        \"duration\": item.get(\"duration\"),\n",
    "        \"width\": chosen.get(\"width\") if chosen else None,\n",
    "        \"height\": chosen.get(\"height\") if chosen else None,\n",
    "        \"provider\": \"pexels\",\n",
    "        \"license\": \"pexels\",\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def fetch_pexels_for_query(query: str, top_k_v: int = MAX_VIDEOS_PER_QUERY, top_k_i: int = MAX_IMAGES_PER_QUERY) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    results = {\"videos\": [], \"images\": []}\n",
    "    try:\n",
    "        vresp = pexels_search_videos(query, per_page=top_k_v)\n",
    "        videos = vresp.get(\"videos\", [])\n",
    "        for v in videos[:top_k_v]:\n",
    "            norm = normalize_video_item(v)\n",
    "            results[\"videos\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] video search failed for query '{query}': {e}\")\n",
    "    try:\n",
    "        presp = pexels_search_photos(query, per_page=top_k_i)\n",
    "        photos = presp.get(\"photos\", [])\n",
    "        for p in photos[:top_k_i]:\n",
    "            norm = normalize_photo_item(p)\n",
    "            results[\"images\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] photo search failed for query '{query}': {e}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263ac7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 4) Freesound API helpers (audio)\n",
    "# ---------------------\n",
    "def freesound_search(query: str, page_size: int = MAX_AUDIOS_PER_QUERY) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search Freesound using text search.\n",
    "    Returns the parsed JSON results (the 'results' list contains items).\n",
    "    \"\"\"\n",
    "    params = {\"query\": query, \"page_size\": page_size, \"fields\": \"id,name,previews,duration,username,tags,license\"}\n",
    "    r = requests.get(FREESOUND_SEARCH, headers=FREESOUND_HEADERS, params=params, timeout=12)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def normalize_freesound_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Normalize a Freesound search result to our asset dict.\n",
    "    We'll prefer the high-quality preview URL for prototyping (preview-hq-mp3 or preview-hq-ogg)\n",
    "    \"\"\"\n",
    "    previews = item.get(\"previews\", {}) or {}\n",
    "    preview_url = previews.get(\"preview-hq-mp3\") or previews.get(\"preview-hq-ogg\") or previews.get(\"preview-lq-mp3\")\n",
    "    return {\n",
    "        \"id\": f\"audio_fs_{item.get('id')}\",\n",
    "        \"type\": \"audio\",\n",
    "        \"url\": preview_url,\n",
    "        \"duration\": item.get(\"duration\"),\n",
    "        \"title\": item.get(\"name\"),\n",
    "        \"uploader\": item.get(\"username\"),\n",
    "        \"tags\": item.get(\"tags\", []),\n",
    "        \"provider\": \"freesound\",\n",
    "        \"license\": item.get(\"license\"),\n",
    "        \"meta\": item,\n",
    "    }\n",
    "\n",
    "def fetch_freesound_for_query(query: str, top_k: int = MAX_AUDIOS_PER_QUERY) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    results = {\"audios\": []}\n",
    "    try:\n",
    "        resp = freesound_search(query, page_size=top_k)\n",
    "        for item in resp.get(\"results\", [])[:top_k]:\n",
    "            norm = normalize_freesound_item(item)\n",
    "            # only include if preview URL exists\n",
    "            if norm.get(\"url\"):\n",
    "                results[\"audios\"].append(norm)\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] Freesound search failed for query '{query}': {e}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377baf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 5) Classification helpers (AUDIO)\n",
    "# For audio: we'll read metadata via mutagen and attempt a small RMS loudness estimate when possible\n",
    "def classify_audio_item(audio_asset: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classify an audio item using:\n",
    "      - duration (from metadata or provider)\n",
    "      - format/file type (from url extension)\n",
    "      - uploader and tags (from provider)\n",
    "      - approximate RMS loudness estimate (best-effort, optional)\n",
    "    Returns a classification dict to attach to the manifest.\n",
    "    \"\"\"\n",
    "    url = audio_asset.get(\"url\")\n",
    "    cls = {\n",
    "        \"duration_seconds\": audio_asset.get(\"duration\"),\n",
    "        \"file_format\": None,\n",
    "        \"uploader\": audio_asset.get(\"uploader\"),\n",
    "        \"tags\": audio_asset.get(\"tags\", []),\n",
    "        \"license\": audio_asset.get(\"license\"),\n",
    "        \"loudness_rms\": None,\n",
    "        \"mood_tags\": [],\n",
    "        \"mood_confidence\": 0.0,\n",
    "        \"notes\": \"\"\n",
    "    }\n",
    "\n",
    "    if not url:\n",
    "        cls[\"notes\"] = \"no_url\"\n",
    "        return cls\n",
    "\n",
    "    # infer file format from url\n",
    "    lower = url.lower()\n",
    "    if lower.endswith(\".mp3\"):\n",
    "        cls[\"file_format\"] = \"mp3\"\n",
    "    elif lower.endswith(\".ogg\") or lower.endswith(\".oga\"):\n",
    "        cls[\"file_format\"] = \"ogg\"\n",
    "    elif lower.endswith(\".wav\"):\n",
    "        cls[\"file_format\"] = \"wav\"\n",
    "    else:\n",
    "        # try to parse from headers\n",
    "        try:\n",
    "            head = requests.head(url, timeout=8, allow_redirects=True)\n",
    "            ctype = head.headers.get(\"content-type\", \"\")\n",
    "            if \"mpeg\" in ctype or \"mp3\" in ctype:\n",
    "                cls[\"file_format\"] = \"mp3\"\n",
    "            elif \"wav\" in ctype:\n",
    "                cls[\"file_format\"] = \"wav\"\n",
    "            elif \"ogg\" in ctype:\n",
    "                cls[\"file_format\"] = \"ogg\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # download preview bytes (safe: previews are small). We'll limit bytes to e.g. 3 MB\n",
    "    audio_bytes = None\n",
    "    try:\n",
    "        audio_bytes = download_bytes(url, max_bytes=3 * 1024 * 1024, timeout=10)\n",
    "    except Exception:\n",
    "        audio_bytes = None\n",
    "\n",
    "    # use mutagen to read metadata/duration if possible\n",
    "    if audio_bytes:\n",
    "        try:\n",
    "            tmp = \"tmp_audio_preview\"\n",
    "            # try to guess extension from url or format; mutagen handles from buffer if saved to file\n",
    "            if cls[\"file_format\"]:\n",
    "                tmp_path = f\"{tmp}.{cls['file_format']}\"\n",
    "            else:\n",
    "                tmp_path = tmp + \".bin\"\n",
    "            with open(tmp_path, \"wb\") as f:\n",
    "                f.write(audio_bytes)\n",
    "            af = MutagenFile(tmp_path)\n",
    "            if af is not None:\n",
    "                # length in seconds\n",
    "                if hasattr(af.info, \"length\"):\n",
    "                    cls[\"duration_seconds\"] = float(af.info.length)\n",
    "                # sample rate\n",
    "                if hasattr(af.info, \"sample_rate\"):\n",
    "                    cls[\"sample_rate\"] = int(getattr(af.info, \"sample_rate\"))\n",
    "                # channels\n",
    "                if hasattr(af.info, \"channels\"):\n",
    "                    cls[\"channels\"] = int(getattr(af.info, \"channels\"))\n",
    "            # small RMS estimate (using numpy wav decode if wav or if mutagen gives raw data is complex)\n",
    "            # We'll attempt a simple RMS for WAV using cv2.imdecode as fallback for small previews\n",
    "            if cls.get(\"file_format\") == \"wav\":\n",
    "                try:\n",
    "                    import wave, struct\n",
    "                    with wave.open(tmp_path, 'rb') as w:\n",
    "                        frames = w.readframes(min(44100, w.getnframes()))\n",
    "                        if w.getsampwidth() == 2:\n",
    "                            fmt = \"<{}h\".format(len(frames)//2)\n",
    "                            ints = struct.unpack(fmt, frames)\n",
    "                            arr = np.array(ints, dtype=np.float32)\n",
    "                            rms = float(np.sqrt(np.mean((arr/32768.0)**2)))\n",
    "                            cls[\"loudness_rms\"] = round(rms, 5)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            cls[\"notes\"] += f\"mutagen_failed:{e};\"\n",
    "        finally:\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # simple mood tags based on provider tags & duration heuristics\n",
    "    mood_tags = []\n",
    "    reason = []\n",
    "    tags = [t.lower() for t in (audio_asset.get(\"tags\") or [])]\n",
    "    if any(t in tags for t in (\"ambient\", \"calm\", \"relax\", \"peaceful\", \"meditation\")):\n",
    "        mood_tags.append(\"calm\")\n",
    "        reason.append(\"ambient_tag\")\n",
    "    if any(t in tags for t in (\"dramatic\", \"tension\", \"suspense\", \"intense\")):\n",
    "        mood_tags.append(\"tense\")\n",
    "        reason.append(\"dramatic_tag\")\n",
    "    if any(t in tags for t in (\"happy\",\"upbeat\",\"bright\")):\n",
    "        mood_tags.append(\"uplifting\")\n",
    "        reason.append(\"happy_tag\")\n",
    "    # duration-based heuristics\n",
    "    dur = cls.get(\"duration_seconds\")\n",
    "    if dur:\n",
    "        if dur < 2.0:\n",
    "            mood_tags.append(\"sfx\")\n",
    "            reason.append(\"short_duration\")\n",
    "        elif dur >= 30 and not mood_tags:\n",
    "            mood_tags.append(\"background\")\n",
    "            reason.append(\"long_duration\")\n",
    "    # dedupe & confidence\n",
    "    mood_tags = list(dict.fromkeys(mood_tags))[:3]\n",
    "    conf = 0.5 + min(0.3, 0.1 * len(mood_tags))\n",
    "    cls[\"mood_tags\"] = mood_tags\n",
    "    cls[\"mood_confidence\"] = round(min(0.99, conf), 2)\n",
    "    if reason:\n",
    "        cls[\"notes\"] += \"mood_reason:\" + \";\".join(reason)\n",
    "    return cls\n",
    "\n",
    "# ---------------------\n",
    "# Utility: download bytes (shared)\n",
    "# ---------------------\n",
    "def download_bytes(url: str, max_bytes: Optional[int] = None, timeout: int = 10) -> Optional[bytes]:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        if max_bytes:\n",
    "            r = requests.get(url, stream=True, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            buf = io.BytesIO()\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if not chunk:\n",
    "                    break\n",
    "                buf.write(chunk)\n",
    "                if buf.tell() >= max_bytes:\n",
    "                    break\n",
    "            return buf.getvalue()\n",
    "        else:\n",
    "            r = requests.get(url, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            return r.content\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b03c39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Classification helpers (VIDEO/IMAGE)\n",
    "\n",
    "_face_cascade = None\n",
    "def _get_face_cascade():\n",
    "    global _face_cascade\n",
    "    if _face_cascade is None:\n",
    "        cascade_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "        _face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    return _face_cascade\n",
    "\n",
    "def download_bytes(url: str, max_bytes: Optional[int] = None, timeout: int = 12) -> Optional[bytes]:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        if max_bytes:\n",
    "            r = requests.get(url, stream=True, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            buf = io.BytesIO()\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if not chunk:\n",
    "                    break\n",
    "                buf.write(chunk)\n",
    "                if buf.tell() >= max_bytes:\n",
    "                    break\n",
    "            return buf.getvalue()\n",
    "        else:\n",
    "            r = requests.get(url, timeout=timeout, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            return r.content\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def sample_frames_from_video(url_or_path: str, n_frames: int = 6) -> List[np.ndarray]:\n",
    "    cap = cv2.VideoCapture(url_or_path)\n",
    "    if not cap.isOpened():\n",
    "        try:\n",
    "            data = download_bytes(url_or_path)\n",
    "            if not data:\n",
    "                return []\n",
    "            tmp = \"tmp_asset_video.bin\"\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                f.write(data)\n",
    "            cap = cv2.VideoCapture(tmp)\n",
    "            if not cap.isOpened():\n",
    "                return []\n",
    "        except Exception:\n",
    "            return []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if frame_count <= 0:\n",
    "        frames = []\n",
    "        for _ in range(n_frames):\n",
    "            ret, f = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "        cap.release()\n",
    "        return frames\n",
    "    indices = np.linspace(0, max(0, frame_count - 1), num=min(n_frames, frame_count), dtype=int)\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, f = cap.read()\n",
    "        if not ret or f is None:\n",
    "            continue\n",
    "        frames.append(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def sample_frames_from_image(url_or_path: str) -> List[np.ndarray]:\n",
    "    b = download_bytes(url_or_path)\n",
    "    if not b:\n",
    "        return []\n",
    "    try:\n",
    "        im = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "        arr = np.array(im)\n",
    "        return [arr]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def dominant_colors_from_rgb_array(arr: np.ndarray, top_k: int = 3) -> List[str]:\n",
    "    try:\n",
    "        im = Image.fromarray(arr)\n",
    "        small = im.resize((200, 200))\n",
    "        pal = small.convert(\"P\", palette=Image.ADAPTIVE, colors=top_k)\n",
    "        palette = pal.getpalette()\n",
    "        color_counts = pal.getcolors()\n",
    "        color_counts.sort(reverse=True)\n",
    "        dominant = []\n",
    "        for count, idx in color_counts[:top_k]:\n",
    "            r = palette[idx*3]; g = palette[idx*3+1]; b = palette[idx*3+2]\n",
    "            dominant.append('#{:02x}{:02x}{:02x}'.format(r,g,b))\n",
    "        return dominant\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def compute_motion_intensity(frames: List[np.ndarray]) -> (str, float):\n",
    "    if not frames or len(frames) < 2:\n",
    "        return (\"none\", 0.0)\n",
    "    mags = []\n",
    "    for i in range(1, len(frames)):\n",
    "        a = cv2.cvtColor(frames[i-1], cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
    "        b = cv2.cvtColor(frames[i], cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
    "        diff = np.abs(b - a)\n",
    "        mags.append(diff.mean())\n",
    "    mean_mag = float(np.mean(mags)) if mags else 0.0\n",
    "    if mean_mag < 2.5:\n",
    "        band = \"low\"\n",
    "    elif mean_mag < 8.0:\n",
    "        band = \"medium\"\n",
    "    else:\n",
    "        band = \"high\"\n",
    "    return (band, mean_mag)\n",
    "\n",
    "def estimate_camera_move(frames: List[np.ndarray]) -> (str, float):\n",
    "    if not frames or len(frames) < 2:\n",
    "        return (\"unknown\", 0.0)\n",
    "    try:\n",
    "        prev = cv2.cvtColor(frames[0], cv2.COLOR_RGB2GRAY)\n",
    "        nxt = cv2.cvtColor(frames[-1], cv2.COLOR_RGB2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev, nxt, None,\n",
    "                                            pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                            iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        avg_mag = float(np.mean(mag))\n",
    "        avg_dx = float(np.mean(flow[...,0]))\n",
    "        avg_dy = float(np.mean(flow[...,1]))\n",
    "        if avg_mag < 0.5:\n",
    "            return (\"static\", avg_mag)\n",
    "        if abs(avg_dx) > abs(avg_dy) * 1.2:\n",
    "            return (\"pan\", avg_mag)\n",
    "        if abs(avg_dy) > abs(avg_dx) * 1.2:\n",
    "            return (\"tilt\", avg_mag)\n",
    "        return (\"dolly_or_forward\", avg_mag)\n",
    "    except Exception:\n",
    "        return (\"unknown\", 0.0)\n",
    "\n",
    "# YOLO wrapper\n",
    "_yolo_model = None\n",
    "def _get_yolo_model():\n",
    "    global _yolo_model\n",
    "    if not _YOLO_AVAILABLE:\n",
    "        return None\n",
    "    if _yolo_model is None:\n",
    "        _yolo_model = YOLO(\"yolov8n.pt\")\n",
    "    return _yolo_model\n",
    "\n",
    "def detect_with_yolo_on_frames(frames: List[np.ndarray]) -> Dict[str, Any]:\n",
    "    model = _get_yolo_model()\n",
    "    if model is None or not frames:\n",
    "        return {\"objects\": [], \"contains_people\": False, \"person_count\": 0}\n",
    "    try:\n",
    "        frame = frames[0]\n",
    "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)\n",
    "        dets = []\n",
    "        contains_people = False\n",
    "        person_count = 0\n",
    "        if results and len(results) > 0:\n",
    "            r = results[0]\n",
    "            boxes = getattr(r, \"boxes\", []) or []\n",
    "            for b in boxes:\n",
    "                try:\n",
    "                    cls = int(b.cls.cpu().numpy()[0]) if hasattr(b, 'cls') else int(b.cls[0])\n",
    "                    label = model.names.get(cls, str(cls)) if hasattr(model, \"names\") else str(cls)\n",
    "                    conf = float(b.conf.cpu().numpy()[0]) if hasattr(b, 'conf') else float(b.conf[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "                dets.append({\"label\": label, \"conf\": conf})\n",
    "                if label.lower() in (\"person\", \"people\"):\n",
    "                    contains_people = True\n",
    "                    person_count += 1\n",
    "        return {\"objects\": dets, \"contains_people\": contains_people, \"person_count\": person_count}\n",
    "    except Exception:\n",
    "        return {\"objects\": [], \"contains_people\": False, \"person_count\": 0}\n",
    "\n",
    "def detect_faces_on_frames(frames: List[np.ndarray]) -> Dict[str, Any]:\n",
    "    face_cascade = _get_face_cascade()\n",
    "    if face_cascade is None or not frames:\n",
    "        return {\"contains_people\": False, \"person_count\": 0, \"objects\": []}\n",
    "    count = 0\n",
    "    for frame in frames:\n",
    "        try:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30,30))\n",
    "            count += len(faces)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return {\"contains_people\": (count > 0), \"person_count\": count, \"objects\": []}\n",
    "\n",
    "def infer_mood_tags(dominant_colors: List[str], motion_band: str, contains_people: bool, objects: List[Dict]) -> (List[str], float, str):\n",
    "    tags = []; reason_terms = []; temp = 0\n",
    "    if dominant_colors:\n",
    "        def hex_to_rgb(h):\n",
    "            h = h.lstrip('#')\n",
    "            return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "        try:\n",
    "            r,g,b = hex_to_rgb(dominant_colors[0])\n",
    "            temp = (r - b) / 255.0\n",
    "        except Exception:\n",
    "            temp = 0\n",
    "    if motion_band in (\"none\",\"low\"):\n",
    "        if temp > 0.05:\n",
    "            tags.extend([\"calm\", \"nostalgic\"]); reason_terms.append(\"warm_palette+low_motion\")\n",
    "        else:\n",
    "            tags.extend([\"calm\"]); reason_terms.append(\"cool+low_motion\")\n",
    "    elif motion_band == \"medium\":\n",
    "        if temp > 0.05:\n",
    "            tags.extend([\"gentle\", \"pleasant\"]); reason_terms.append(\"warm+medium_motion\")\n",
    "        else:\n",
    "            tags.extend([\"moving\",\"reflective\"]); reason_terms.append(\"cool+medium_motion\")\n",
    "    else:\n",
    "        tags.extend([\"energetic\",\"urgent\"]); reason_terms.append(\"high_motion\")\n",
    "    obj_labels = [o[\"label\"].lower() for o in objects] if objects else []\n",
    "    if contains_people and \"calm\" in tags:\n",
    "        tags.append(\"intimate\"); reason_terms.append(\"people+calm\")\n",
    "    if any(x in obj_labels for x in (\"ocean\",\"beach\",\"shore\",\"wave\",\"sea\",\"kite\")):\n",
    "        if \"calm\" in tags or temp > 0.05:\n",
    "            tags = [\"calm\",\"poignant\"]; reason_terms.append(\"ocean+kite+warm\")\n",
    "    tags = list(dict.fromkeys(tags))[:3]\n",
    "    score = 0.5\n",
    "    if dominant_colors: score += 0.15\n",
    "    if motion_band != \"none\": score += 0.15\n",
    "    if contains_people or objects: score += 0.15\n",
    "    score = min(0.99, score)\n",
    "    reason = \";\".join(reason_terms) if reason_terms else \"\"\n",
    "    return tags, round(score,2), reason\n",
    "\n",
    "def classify_asset(url_or_path: str, asset_type: str = None, sample_frames_count: int = 6) -> Dict[str, Any]:\n",
    "    if asset_type is None:\n",
    "        l = url_or_path.lower()\n",
    "        if any(l.endswith(x) for x in (\".mp4\",\".mov\",\".webm\",\".mkv\",\".avi\")):\n",
    "            asset_type = \"video\"\n",
    "        elif any(l.endswith(x) for x in (\".jpg\",\".jpeg\",\".png\",\".webp\")):\n",
    "            asset_type = \"image\"\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(url_or_path)\n",
    "            if cap and cap.isOpened():\n",
    "                asset_type = \"video\"; cap.release()\n",
    "            else:\n",
    "                asset_type = \"image\"\n",
    "    frames = sample_frames_from_video(url_or_path, n_frames=sample_frames_count) if asset_type==\"video\" else sample_frames_from_image(url_or_path)\n",
    "    classification = {\n",
    "        \"contains_people\": False, \"person_count\": 0, \"objects\": [],\n",
    "        \"motion_intensity\": \"none\", \"motion_metric\": 0.0,\n",
    "        \"camera_move\": \"unknown\", \"camera_move_metric\": 0.0,\n",
    "        \"dominant_colors\": [], \"mood_tags\": [], \"mood_confidence\": 0.0, \"mood_reason\": \"\", \"notes\": \"\"\n",
    "    }\n",
    "    if not frames:\n",
    "        classification[\"notes\"]=\"no_frames_obtained\"\n",
    "        return {\"url\":url_or_path, \"type\":asset_type, \"classification\":classification}\n",
    "    try:\n",
    "        dom = dominant_colors_from_rgb_array(frames[0], top_k=3)\n",
    "        classification[\"dominant_colors\"]=dom\n",
    "    except Exception:\n",
    "        classification[\"dominant_colors\"]=[]\n",
    "    if _YOLO_AVAILABLE:\n",
    "        try:\n",
    "            det = detect_with_yolo_on_frames(frames)\n",
    "            classification[\"objects\"]=det.get(\"objects\",[])\n",
    "            classification[\"contains_people\"]=bool(det.get(\"contains_people\",False))\n",
    "            classification[\"person_count\"]=int(det.get(\"person_count\",0))\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"]+=f\"yolo_failed:{e};\"\n",
    "    else:\n",
    "        try:\n",
    "            det = detect_faces_on_frames(frames)\n",
    "            classification[\"contains_people\"]=det.get(\"contains_people\",False)\n",
    "            classification[\"person_count\"]=det.get(\"person_count\",0)\n",
    "            classification[\"objects\"]=[]\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"]+=f\"face_failed:{e};\"\n",
    "    try:\n",
    "        band, metric = compute_motion_intensity(frames)\n",
    "        classification[\"motion_intensity\"]=band; classification[\"motion_metric\"]=round(metric,3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"motion_failed:{e};\"\n",
    "    try:\n",
    "        cam, cam_metric = estimate_camera_move(frames)\n",
    "        classification[\"camera_move\"]=cam; classification[\"camera_move_metric\"]=round(cam_metric,3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"camera_move_failed:{e};\"\n",
    "    try:\n",
    "        tags, conf, reason = infer_mood_tags(classification[\"dominant_colors\"], classification[\"motion_intensity\"], classification[\"contains_people\"], classification[\"objects\"])\n",
    "        classification[\"mood_tags\"]=tags; classification[\"mood_confidence\"]=conf; classification[\"mood_reason\"]=reason\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"]+=f\"mood_failed:{e};\"\n",
    "    return {\"url\":url_or_path, \"type\":asset_type, \"classification\":classification}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6ec108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_asset(url_or_path: str, asset_type: str = None, sample_frames_count: int = 6) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    A consolidated classify_asset that routes to video/image or audio classification.\n",
    "    \"\"\"\n",
    "    # If asset_type explicitly 'audio', call audio classifier\n",
    "    if asset_type == \"audio\":\n",
    "        return {\"url\": url_or_path, \"type\": \"audio\", \"classification\": classify_audio_item({\"url\": url_or_path, \"tags\": [], \"uploader\": None, \"duration\": None, \"license\": None})}\n",
    "    if asset_type is None:\n",
    "        l = url_or_path.lower()\n",
    "        if any(l.endswith(x) for x in (\".mp4\",\".mov\",\".webm\",\".mkv\",\".avi\")):\n",
    "            asset_type = \"video\"\n",
    "        elif any(l.endswith(x) for x in (\".jpg\",\".jpeg\",\".png\",\".webp\")):\n",
    "            asset_type = \"image\"\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(url_or_path)\n",
    "            if cap and cap.isOpened():\n",
    "                asset_type = \"video\"\n",
    "                cap.release()\n",
    "            else:\n",
    "                asset_type = \"image\"\n",
    "\n",
    "    frames = []\n",
    "    if asset_type == \"video\":\n",
    "        frames = sample_frames_from_video(url_or_path, n_frames=sample_frames_count)\n",
    "    else:\n",
    "        frames = sample_frames_from_image(url_or_path)\n",
    "\n",
    "    classification = {\n",
    "        \"contains_people\": False, \"person_count\": 0, \"objects\": [],\n",
    "        \"motion_intensity\": \"none\", \"motion_metric\": 0.0,\n",
    "        \"camera_move\": \"unknown\", \"camera_move_metric\": 0.0,\n",
    "        \"dominant_colors\": [], \"mood_tags\": [], \"mood_confidence\": 0.0, \"mood_reason\": \"\", \"notes\": \"\"\n",
    "    }\n",
    "\n",
    "    if not frames:\n",
    "        classification[\"notes\"] = \"no_frames_obtained\"\n",
    "        return {\"url\": url_or_path, \"type\": asset_type, \"classification\": classification}\n",
    "\n",
    "    # dominant colors\n",
    "    try:\n",
    "        classification[\"dominant_colors\"] = dominant_colors_from_rgb_array(frames[0], top_k=3)\n",
    "    except Exception:\n",
    "        classification[\"dominant_colors\"] = []\n",
    "\n",
    "    # detection: YOLO if available else Haar faces\n",
    "    if _YOLO_AVAILABLE:\n",
    "        try:\n",
    "            det = detect_with_yolo_on_frames(frames)\n",
    "            classification[\"objects\"] = det.get(\"objects\", [])\n",
    "            classification[\"contains_people\"] = bool(det.get(\"contains_people\", False))\n",
    "            classification[\"person_count\"] = int(det.get(\"person_count\", 0))\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"] += f\"yolo_failed:{e};\"\n",
    "    else:\n",
    "        try:\n",
    "            det = detect_faces_on_frames(frames)\n",
    "            classification[\"contains_people\"] = det.get(\"contains_people\", False)\n",
    "            classification[\"person_count\"] = det.get(\"person_count\", 0)\n",
    "            classification[\"objects\"] = []\n",
    "        except Exception as e:\n",
    "            classification[\"notes\"] += f\"face_failed:{e};\"\n",
    "\n",
    "    # motion\n",
    "    try:\n",
    "        band, metric = compute_motion_intensity(frames)\n",
    "        classification[\"motion_intensity\"] = band\n",
    "        classification[\"motion_metric\"] = round(metric, 3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"] += f\"motion_failed:{e};\"\n",
    "\n",
    "    # camera move\n",
    "    try:\n",
    "        cam, cam_metric = estimate_camera_move(frames)\n",
    "        classification[\"camera_move\"] = cam\n",
    "        classification[\"camera_move_metric\"] = round(cam_metric, 3)\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"] += f\"camera_move_failed:{e};\"\n",
    "\n",
    "    # mood tags (reuse infer_mood_tags)\n",
    "    try:\n",
    "        tags, conf, reason = infer_mood_tags(classification[\"dominant_colors\"], classification[\"motion_intensity\"], classification[\"contains_people\"], classification[\"objects\"])\n",
    "        classification[\"mood_tags\"] = tags\n",
    "        classification[\"mood_confidence\"] = conf\n",
    "        classification[\"mood_reason\"] = reason\n",
    "    except Exception as e:\n",
    "        classification[\"notes\"] += f\"mood_failed:{e};\"\n",
    "\n",
    "    return {\"url\": url_or_path, \"type\": asset_type, \"classification\": classification}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59bb88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 6) Pipeline: fetch (pexels + freesound) + classify + assemble plan\n",
    "# ---------------------\n",
    "def build_plan_fetch_and_classify(prompt_text: str) -> Dict[str, Any]:\n",
    "    shots = ask_model_for_shots(prompt_text, min_shots=1, max_shots=MAX_SHOTS)\n",
    "    plan = {\"prompt\": prompt_text, \"shots\": [], \"asset_manifest\": {}}\n",
    "    manifest_index = 0\n",
    "\n",
    "    for shot in shots:\n",
    "        queries = expand_queries_for_shot(shot)\n",
    "        shot_entry = {\n",
    "            \"id\": shot.get(\"id\"),\n",
    "            \"text_description\": shot.get(\"text_description\"),\n",
    "            \"suggested_duration_seconds\": shot.get(\"suggested_duration_seconds\"),\n",
    "            \"queries_used\": queries,\n",
    "            \"assets\": {\"videos\": [], \"images\": [], \"audios\": []}\n",
    "        }\n",
    "        for q in queries:\n",
    "            print(f\"[INFO] Fetching Pexels for shot {shot.get('id')} query: {q}\")\n",
    "            found_media = fetch_pexels_for_query(q)\n",
    "            # classify videos\n",
    "            for v in found_media.get(\"videos\", []):\n",
    "                url = v.get(\"url\")\n",
    "                if not url:\n",
    "                    continue\n",
    "                if url in [a.get(\"url\") for a in shot_entry[\"assets\"][\"videos\"]]:\n",
    "                    continue\n",
    "                cls = classify_asset(url, asset_type=\"video\", sample_frames_count=4)\n",
    "                manifest_index += 1\n",
    "                aid = f\"video_{manifest_index}\"\n",
    "                plan[\"asset_manifest\"][aid] = {\"url\": url, \"type\": \"video\", \"classification\": cls[\"classification\"], \"meta\": v.get(\"meta\")}\n",
    "                shot_entry[\"assets\"][\"videos\"].append({\"asset_id\": aid, \"url\": url, \"classification\": cls[\"classification\"]})\n",
    "\n",
    "            # classify images\n",
    "            for im in found_media.get(\"images\", []):\n",
    "                url = im.get(\"url\")\n",
    "                if not url:\n",
    "                    continue\n",
    "                if url in [a.get(\"url\") for a in shot_entry[\"assets\"][\"images\"]]:\n",
    "                    continue\n",
    "                cls = classify_asset(url, asset_type=\"image\", sample_frames_count=1)\n",
    "                manifest_index += 1\n",
    "                aid = f\"image_{manifest_index}\"\n",
    "                plan[\"asset_manifest\"][aid] = {\"url\": url, \"type\": \"image\", \"classification\": cls[\"classification\"], \"meta\": im.get(\"meta\")}\n",
    "                shot_entry[\"assets\"][\"images\"].append({\"asset_id\": aid, \"url\": url, \"classification\": cls[\"classification\"]})\n",
    "\n",
    "            # fetch & classify freesound audios for the same query\n",
    "            print(f\"[INFO] Fetching Freesound for shot {shot.get('id')} query: {q}\")\n",
    "            found_audio = fetch_freesound_for_query(q)\n",
    "            for a in found_audio.get(\"audios\", []):\n",
    "                url = a.get(\"url\")\n",
    "                if not url:\n",
    "                    continue\n",
    "                if url in [x.get(\"url\") for x in shot_entry[\"assets\"][\"audios\"]]:\n",
    "                    continue\n",
    "                # classify audio (we have metadata in 'a'), use classify_audio_item\n",
    "                audio_cls = classify_audio_item(a)\n",
    "                manifest_index += 1\n",
    "                aid = f\"audio_{manifest_index}\"\n",
    "                plan[\"asset_manifest\"][aid] = {\"url\": url, \"type\": \"audio\", \"classification\": audio_cls, \"meta\": a.get(\"meta\")}\n",
    "                shot_entry[\"assets\"][\"audios\"].append({\"asset_id\": aid, \"url\": url, \"classification\": audio_cls})\n",
    "\n",
    "            time.sleep(0.25)\n",
    "        plan[\"shots\"].append(shot_entry)\n",
    "    return plan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Building plan, fetching Pexels & Freesound, classifying assets for: Bustling city with vehicles and people - energetic, fast-paced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fetching Pexels for shot shot_1 query: Aerial view of a busy intersection with cars and buses moving rapidly.\n",
      "[INFO] Fetching Freesound for shot shot_1 query: Aerial view of a busy intersection with cars and buses moving rapidly.\n",
      "[INFO] Fetching Pexels for shot shot_1 query: city traffic bustling aerial\n",
      "[INFO] Fetching Freesound for shot shot_1 query: city traffic bustling aerial\n",
      "[INFO] Fetching Pexels for shot shot_1 query: city\n",
      "[INFO] Fetching Freesound for shot shot_1 query: city\n",
      "[INFO] Fetching Pexels for shot shot_2 query: Close-up of pedestrians crossing the street, showcasing diverse groups of people.\n",
      "[INFO] Fetching Freesound for shot shot_2 query: Close-up of pedestrians crossing the street, showcasing diverse groups of people.\n",
      "[INFO] Fetching Pexels for shot shot_2 query: people pedestrians crosswalk diversity\n",
      "[INFO] Fetching Freesound for shot shot_2 query: people pedestrians crosswalk diversity\n",
      "[INFO] Fetching Pexels for shot shot_2 query: people\n",
      "[INFO] Fetching Freesound for shot shot_2 query: people\n",
      "[INFO] Fetching Pexels for shot shot_3 query: Time-lapse of vehicles moving through a busy street, highlighting the flow of traffic.\n",
      "[INFO] Fetching Freesound for shot shot_3 query: Time-lapse of vehicles moving through a busy street, highlighting the flow of traffic.\n",
      "[INFO] Fetching Pexels for shot shot_3 query: time-lapse vehicles traffic movement\n",
      "[INFO] Fetching Freesound for shot shot_3 query: time-lapse vehicles traffic movement\n",
      "[warning] Freesound search failed for query 'time-lapse vehicles traffic movement': HTTPSConnectionPool(host='freesound.org', port=443): Max retries exceeded with url: /apiv2/search/text/?query=time-lapse+vehicles+traffic+movement&page_size=3&fields=id%2Cname%2Cpreviews%2Cduration%2Cusername%2Ctags%2Clicense (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF2850>: Failed to resolve 'freesound.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Pexels for shot shot_3 query: time-lapse\n",
      "[warning] video search failed for query 'time-lapse': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /videos/search?query=time-lapse&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF2AD0>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[warning] photo search failed for query 'time-lapse': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /v1/search?query=time-lapse&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF2990>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Freesound for shot shot_3 query: time-lapse\n",
      "[warning] Freesound search failed for query 'time-lapse': HTTPSConnectionPool(host='freesound.org', port=443): Max retries exceeded with url: /apiv2/search/text/?query=time-lapse&page_size=3&fields=id%2Cname%2Cpreviews%2Cduration%2Cusername%2Ctags%2Clicense (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF2350>: Failed to resolve 'freesound.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Pexels for shot shot_4 query: Wide shot of a crowded market street with vendors and shoppers interacting.\n",
      "[warning] video search failed for query 'Wide shot of a crowded market street with vendors and shoppers interacting.': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /videos/search?query=Wide+shot+of+a+crowded+market+street+with+vendors+and+shoppers+interacting.&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF2E90>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[warning] photo search failed for query 'Wide shot of a crowded market street with vendors and shoppers interacting.': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /v1/search?query=Wide+shot+of+a+crowded+market+street+with+vendors+and+shoppers+interacting.&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF3250>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Freesound for shot shot_4 query: Wide shot of a crowded market street with vendors and shoppers interacting.\n",
      "[warning] Freesound search failed for query 'Wide shot of a crowded market street with vendors and shoppers interacting.': HTTPSConnectionPool(host='freesound.org', port=443): Max retries exceeded with url: /apiv2/search/text/?query=Wide+shot+of+a+crowded+market+street+with+vendors+and+shoppers+interacting.&page_size=3&fields=id%2Cname%2Cpreviews%2Cduration%2Cusername%2Ctags%2Clicense (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF3610>: Failed to resolve 'freesound.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Pexels for shot shot_4 query: market crowd vendors shopping\n",
      "[warning] video search failed for query 'market crowd vendors shopping': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /videos/search?query=market+crowd+vendors+shopping&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF39D0>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[warning] photo search failed for query 'market crowd vendors shopping': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /v1/search?query=market+crowd+vendors+shopping&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABAF3C50>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Freesound for shot shot_4 query: market crowd vendors shopping\n",
      "[warning] Freesound search failed for query 'market crowd vendors shopping': HTTPSConnectionPool(host='freesound.org', port=443): Max retries exceeded with url: /apiv2/search/text/?query=market+crowd+vendors+shopping&page_size=3&fields=id%2Cname%2Cpreviews%2Cduration%2Cusername%2Ctags%2Clicense (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABC18190>: Failed to resolve 'freesound.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Pexels for shot shot_4 query: market\n",
      "[warning] video search failed for query 'market': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /videos/search?query=market&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABC18550>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[warning] photo search failed for query 'market': HTTPSConnectionPool(host='api.pexels.com', port=443): Max retries exceeded with url: /v1/search?query=market&per_page=3 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABC18910>: Failed to resolve 'api.pexels.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "[INFO] Fetching Freesound for shot shot_4 query: market\n",
      "[warning] Freesound search failed for query 'market': HTTPSConnectionPool(host='freesound.org', port=443): Max retries exceeded with url: /apiv2/search/text/?query=market&page_size=3&fields=id%2Cname%2Cpreviews%2Cduration%2Cusername%2Ctags%2Clicense (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000023EABC18CD0>: Failed to resolve 'freesound.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Saved plan_pexels_enriched_with_audio.json\n",
      "{\n",
      "  \"prompt\": \"Bustling city with vehicles and people - energetic, fast-paced\",\n",
      "  \"shots_count\": 4,\n",
      "  \"assets_count\": 53\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# 7) Run & save\n",
    "# ---------------------\n",
    "#Sunset over the ocean - calm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    brief = \"a dog and a cat fightun- energetic, fast-paced\"\n",
    "    print(\"[RUN] Building plan, fetching Pexels & Freesound, classifying assets for:\", brief)\n",
    "    plan = build_plan_fetch_and_classify(brief)\n",
    "    out_path = \"plan_pexels_enriched_with_audio.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(plan, f, indent=2)\n",
    "    print(\"Saved\", out_path)\n",
    "    print(json.dumps({\"prompt\": plan[\"prompt\"], \"shots_count\": len(plan[\"shots\"]), \"assets_count\": len(plan[\"asset_manifest\"])}, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
